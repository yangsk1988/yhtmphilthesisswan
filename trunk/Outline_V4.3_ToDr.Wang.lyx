#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\options 12pt
\use_default_options true
\begin_modules
eqs-within-sections
figs-within-sections
tabs-within-sections
theorems-ams
theorems-sec
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding ascii
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing onehalf
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 3
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 4cm
\topmargin 3cm
\rightmargin 2.5cm
\bottommargin 3cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Consensus Based Signal Processing and its Application in Cloud Detection
\end_layout

\begin_layout Abstract
Distributed Consensus algorithm (DCA) has application in data fusion in
 wireless sensor networks and coordination of multi-agent system.
 Some distributive signal processing based on consensus algorithm , such
 as, local value linear prediction, information flooding and network eigenvalues
 estimation, were introduced in this thesis.
 Finally, a simulation of distributive cloud detection was given, in which
 data acquired by sensor nodes is processed by distributed consensus algorithm.
 A modification to the conventional consensus algorithm is also applied
 to make it possible to find the global log likelihood ratio when signals
 are correlated.
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
In a distributed system, processing information that originally and locally
 acquired by the nodes is often necessary.
 Centralized signal processing require a special node called fusion center.
 Sometimes fusion center has to be involved if the signal processing is
 complicate and it is not possible to find a distributive solution.
 However, fusion center is the most important node in the network that responsib
le for data gathering and data processing.
 Once the fusion center is destroyed or failed, the whole network breaks
 down.
 In addition, limited energy is also a problem for WSN in centralized signal
 processing because data gathering is a energy consuming process.
 Also there is unbalance energy consumption between nodes with different
 communication loads 
\begin_inset CommandInset citation
LatexCommand cite
key "Cristescu2004"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Yuen2008"

\end_inset

.
 In contrast, distributed signal processing involves multiple sensors date
 fusion, can normally be more reliable than single sensor node detection
 
\begin_inset CommandInset citation
LatexCommand cite
key "Chair1986"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Kam1992"

\end_inset

.
 Also the distributed signal processing has the advantages of reliability
 to nodes failure or topology changes as well as balanced energy consumption.
  
\end_layout

\begin_layout Standard
Distributed Average Consensus (DAC) algorithm has received significant attention
 recently because of its robustness and simplicity for processing distributed
 information over networks.
 It have applications in rendezvous, formation control, flocking, attitude
 alignment and wireless sensor networks 
\begin_inset CommandInset citation
LatexCommand cite
key "Ren2007"

\end_inset

.
 For these applications, reaching to an agreement among all the nodes in
 a distributed network is often necessary.
 There are many algorithms developed by now.
 We discuss these DAC algorithms by mainly comparing the convergence rate
 of them.
 The agreement is achieved if local values of nodes converge to a common
 value which is referred to as a consensus value.
 
\end_layout

\begin_layout Standard
In conventional DAC algorithms, each node updates its local value repeatedly
 as a weighted linear combination of its previous local value and those
 from its neighbors.
 The iteration is continued until all the local values converge to a global
 average within a desired error level.
 These methods are referred as asymptotic consensus in 
\begin_inset CommandInset citation
LatexCommand cite
key "Sundaram2007"

\end_inset

.
 By introducing the associated network graph matrix, whose entries are the
 corresponding weights assigned to the edges, the convergence rate of linear
 DAC is determined by the spectral radius of the matrix.
 Commonly, the edge weights are determined by degree of nodes and their
 adjacent node's degrees so that the DAC algorithms would converge 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2009a"

\end_inset

.
 
\end_layout

\begin_layout Standard
To find an algorithm that finds consensus value more quickly, a great deal
 of research interest has been devoted to more sophisticated consensus algorithm
s 
\begin_inset CommandInset citation
LatexCommand cite
key "Sundaram2007"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "Moreau2004"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "Khan2010"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "Li2010"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokiopoulou2007"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand cite
key "Cavalcante2010"

\end_inset

.
 For the first order linear consensus algorithm, convergence rate is increased
 by casting graph matrix spectral radius minimization problem as a convex
 optimization problem 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset

, but solving such problem requires knowledge of the whole network topology.
 Second order or high-order DAC can be introduced to improve the convergence
 rate.
 It also requires knowledge of network topology but only eigenvalues of
 Laplacian matrix 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2009a"

\end_inset

, which only depends on the network graph and is very useful tool to analyze
 the convergence rate.
 Because of the properties of the Laplacian matrix, its first smallest eigenvalu
e is always zero and the second smallest eigenvalue (called the algebraic
 connectivity of the graph, or denoted as the Fiedler eigenvalue) is equal
 to zero if and only if the graph is not connected 
\begin_inset CommandInset citation
LatexCommand cite
key "MiroslavFiedler1973"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Russell1994"

\end_inset

.
 Theoretically, higher order algorithm will potentially have a higher convergenc
e rate.

\series bold
 
\series default
However, there are very little improvement when introducing the order larger
 than fourth 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2010"

\end_inset

.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "Moreau2004"

\end_inset

, the consensus problem is treated in a continuous-time manner and the local
 value is described by a set of differential equations.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Khan2010"

\end_inset

 considers higher dimensional consensus (HDC), which is a general class
 of linear distributed algorithms for large-scale networks.
 In HDC, the network nodes are partitioned into “anchors”, whose states
 are fixed over the iterations, and “sensors”, whose states are updated
 by the algorithm.
 And 
\begin_inset CommandInset citation
LatexCommand cite
key "Li2010"

\end_inset

 proposed a class of location-aided distributed averaging algorithms which
 accelerate the slow convergence by overcoming the diffusive behavior of
 reversible chains.
 
\end_layout

\begin_layout Standard
It needs mentioned that some novel methods increase the convergence rate
 by taking a number of consecutive local values obtained by asymptotic consensus
 into consideration.
 Motivated by the Kalman filter scheme, a consensus update scheme is proposed
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Ren2005"

\end_inset

, which treats the final consensus value as the system state, and it is
 shown that algorithm is convergent for strongly connected networks.
 Later, a modification to the basic Kalman filter algorithm is presented
 to ensure the Kalman Filter converges to an unbiased estimate 
\begin_inset CommandInset citation
LatexCommand cite
key "Alighanbari2006"

\end_inset

.
 The method in 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokiopoulou2007"

\end_inset

 applies scalar epsilon algorithm (SEA) to the local values sequence in
 each node to accelerate the convergence.
 The main disadvantage of this method is that it uses all previous estimates
 and its robustness against changes in the network topology is questionable
 
\begin_inset CommandInset citation
LatexCommand cite
key "Cavalcante2010"

\end_inset

.
 In turn, Cavalcante and Mulgrew 
\begin_inset CommandInset citation
LatexCommand cite
key "Cavalcante2010"

\end_inset

 introduces an adaptive filter algorithm to find the consensus value by
 iteratively updating the coefficients of an adaptive filter.
 Another novel method 
\begin_inset CommandInset citation
LatexCommand cite
key "Sundaram2007"

\end_inset

 tries to find the z-transform of the nodes value, and uses final value
 theorem to obtain the consensus value.
 However, every node having the knowledge of network topology is a strict
 condition.
 Therefore, a decentralized method is proposed to computer the matrix polynomial.
 This method requires several runs of the consensus algorithm initialized
 with a set of linear independent vectors.
\end_layout

\begin_layout Standard
Motivated by the works in 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokiopoulou2007"

\end_inset

, we try to rewrite the local value vectors in another form which reveals
 an important property of the algorithm.
 Based on this fact, we propose some signal processing techniques.
 For example, with the proposed consensus finding filter, each node could
 estimate the consensus value by passing through consecutive local values
 obtained by the first order linear DAC algorithm without more information
 exchanged between nodes.
\end_layout

\begin_layout Subsection
Categories of Consensus Algorithm
\end_layout

\begin_layout Standard
To introduce the distributive consensus algorithm, we may started from one
 of the simplest algorithm in their family.
 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Categories-of-Discrete-time"

\end_inset

 only shows the branch of discrete-time distributive consensus algorithm,
 continuous-time consensus algorithm has some similarities with discrete-time
 ones.
 However, their performance is quite different when Gaussian white noise
 exists, so it can be categorized in another branch.
 As shown in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:DT-First-Order-DAC"

\end_inset

, the first order DAC algorithm is the simplest algorithm that can solve
 the consensus problem in a number of iteration.
 It's convergence rate is related to the spectral radius of a graph dependent
 matrix.
 So the optimization problem is to find the optimal matrix with minimum
 spectral radius.
 However, global information of the graph matrix must be available.
 In distributed methods, this is a quite strong condition.
 Without the global information, best constant and metropolitan matrix can
 be the sub-optimal solution to the consensus problem 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset

.
 The first order DAC algorithm is one of the asymptotic algorithms together
 with higher-order DAC algorithm.
 The demand of higher-order algorithm is mainly because the requirement
 for a fast convergence rate is always a matter of issue.
 In 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:Discrete-High-Order"

\end_inset

, we introduced higher-order DAC algorithm, which could have faster convergence
 rate, and no additional requirement and communication cost is required
 compared with first-order DAC 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2010"

\end_inset

.
 Therefore, it is shortly applied into practical consensus problem after
 invented.
 
\end_layout

\begin_layout Standard
Some of the novel methods can solve the average consensus problem in finite
 number of iterations.
 These methods are referred to as finite-time consensus algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "Sundaram2007"

\end_inset

.
 It actually a very sophisticated signal processing technique that find
 the asymptotically stable equilibrium 
\begin_inset Formula $\bar{x}$
\end_inset

 by extrapolation, see 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sec:Finite-Time-Distributed-Consensu"

\end_inset

.
 A derivative of finite-time consensus algorithm is the adaptive filter
 algorithm for average consensus .
 It applies an adaptive filter algorithm to asymptotically converge the
 set of parameters which are required in the computation of consensus value
 
\begin_inset CommandInset citation
LatexCommand cite
key "Cavalcante2010"

\end_inset

.
 Reader can find the definition of these parameters in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:Find-the-Consensus"

\end_inset

.
 As a contribution of this thesis, a method to calculate these necessary
 parameters by inverting Toeplitz matrix is introduced in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:Finite-time-Consensus-on"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename Graph/Categories of DAC_Nor.pdf
	width 13.5cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Categories-of-Discrete-time"

\end_inset

Categories of Discrete-time Consensus Algorithm
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Consensus-problem-on"

\end_inset

Consensus problem on Graphs
\end_layout

\begin_layout Standard
Consider a network (connected graph) 
\begin_inset Formula $\mathcal{G}=\left(\mathcal{V},\mathcal{E},{\cal A}\right)$
\end_inset

 be a weighted digraph (or undirected graph) consisted by a set of nodes
 
\begin_inset Formula $\mathcal{V}=\left\{ 1,2,...,n\right\} $
\end_inset

, a set of edges 
\begin_inset Formula $\mathcal{E}\subseteq\mathcal{V}\times\mathcal{V}$
\end_inset

 and a weighted adjacency matrix 
\begin_inset Formula ${\cal A}=\left[a_{ij}\right]$
\end_inset

.
 The edge 
\begin_inset Formula $\left(i,j\right)\in\mathfrak{\mathcal{E}}$
\end_inset

 is an unordered pair of distinct nodes, associated with an element in the
 adjacency matrix 
\begin_inset Formula ${\cal A}$
\end_inset

, i.e.
 
\begin_inset Formula $\left(i,j\right)\in\mathfrak{\mathcal{E}}\Leftrightarrow a_{ij}$
\end_inset

.
 we assume 
\begin_inset Formula $a_{ij}=0$
\end_inset

, if 
\begin_inset Formula $j\notin{\cal N}_{i}$
\end_inset

 (note that 
\begin_inset Formula $a_{ii}=0$
\end_inset

, as 
\begin_inset Formula $i\notin{\cal N}_{i}$
\end_inset

) for all 
\begin_inset Formula $i\in\mathcal{V}$
\end_inset

..
 Moreover, the set of neighbors of node 
\begin_inset Formula $i$
\end_inset

 is denoted by 
\begin_inset Formula $\mathcal{N}_{i}=\text{ }\left\{ j\in{\cal V}|\left(i,j\right)\in\mathcal{E}\right\} $
\end_inset

, an node 
\begin_inset Formula $i$
\end_inset

 can only transmit information to other nodes that belong to the neighbors
 set.
 
\end_layout

\begin_layout Standard
Suppose each node holds an initial scalar value 
\begin_inset Formula $x_{i}\left(0\right)\in R$
\end_inset

, which can be a value that locally acquired by node representing physical
 quantities including temperature, humidity, illumination, attitude, and
 so on.
 We define the local value vector 
\begin_inset Formula $\mathbf{x}\left(0\right)=\left[x_{1}\left(0\right),...,x_{n}\left(0\right)\right]^{T}\in R^{n}$
\end_inset

 to represent all the initial values on the network.
 The network is said to be reached a consensus if and only if 
\begin_inset Formula $x_{i}=x_{j}$
\end_inset

, for all nodes 
\begin_inset Formula $i,j\in{\cal V},i\neq j$
\end_inset

.
 In the other words, all the nodes of the network are in an agreement, the
 common value of all nodes is called the consensus value.
 
\end_layout

\begin_layout Standard
To describe the behavior of each node or agent, suppose each node has the
 following dynamics 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\dot{x}_{i}=f\left(x_{i},u_{i}\right),i\in{\cal V}
\end{equation}

\end_inset

and the graph (or network) is a system has the dynamics
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{\dot{x}}=F\left(\mathbf{x},\mathbf{u}\right)\label{eq:system dynamic}
\end{equation}

\end_inset

where 
\begin_inset Formula $F\left(\mathbf{x},\mathbf{u}\right)$
\end_inset

 is the columnwise concatenation of individual dynamics 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $f\left(x_{i},u_{i}\right)$
\end_inset

, for all node 
\begin_inset Formula $i=1,\ldots,n$
\end_inset

.
 In an ad-hoc network with the mobile nodes, the topology 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Formula $G$
\end_inset


\series bold
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
is switching and the system will updating its 
\begin_inset Formula $F\left(\mathbf{x},\mathbf{u}\right)$
\end_inset

 from time to time.
 
\end_layout

\begin_layout Standard
The input or feedback 
\begin_inset Formula $u_{i}$
\end_inset

 in the node's dynamic is a function of the historical states of node 
\begin_inset Formula $i$
\end_inset

 and its neighbors
\begin_inset Formula 
\begin{equation}
u_{i}=g\left(x_{j_{1}},x_{j_{2}},\ldots,x_{j_{m_{i}}}\right)\label{eq:consensus protocol}
\end{equation}

\end_inset

where 
\begin_inset Formula $j_{1},\ldots,j_{m_{i}}$
\end_inset

 are the node indexes that belong to the set 
\begin_inset Formula $\left\{ i\right\} \cup{\cal N}_{i}$
\end_inset

.
 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:consensus protocol"

\end_inset

 is called a consensus protocol under topology 
\begin_inset Formula $G$
\end_inset

.
 If the network graph is not fully connected, it is said to be a distributive
 consensus protocol.
 
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula ${\cal X}:R^{n}\to R$
\end_inset

 be a function of 
\begin_inset Formula $n$
\end_inset

 variables of 
\begin_inset Formula $x_{1},x_{2},\ldots,x_{n}$
\end_inset

 and let 
\begin_inset Formula $\mathbf{x}\left(0\right)$
\end_inset

 denotes the initial condition of the network.
 The 
\begin_inset Formula ${\cal X}$
\end_inset

-consensus problem is a distributive method to calculate the consensus value
 
\begin_inset Formula ${\cal X}\left(\mathbf{x}\left(0\right)\right)$
\end_inset

 in a graph 
\begin_inset Formula $G$
\end_inset

.
 
\end_layout

\begin_layout Standard
Actually, there are different consensus problems too.
 For instance, the average consensus 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula ${\cal X}\left(\mathbf{x}\right)=\frac{1}{n}\sum_{i=1}^{n}x_{i}\left(0\right)$
\end_inset

,
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 maximum consensus 
\begin_inset Formula ${\cal X}\left(\mathbf{x}\right)=\max\left(\mathbf{x}\right)$
\end_inset

, minimum consensus 
\begin_inset Formula ${\cal X}\left(\mathbf{x}\right)=\min\left(\mathbf{x}\right)$
\end_inset

 and variance consensus 
\begin_inset Formula ${\cal X}\left(\mathbf{x}\right)=\mbox{var}\left(\mathbf{x}\right)$
\end_inset

 are given by their expressions respectively.
 The average consensus is a special case of consensus problem, which computing
 the average of all initial values 
\begin_inset Formula $\overline{x}=\mbox{mean}\left(\mathbf{x}\right)=\frac{1}{n}\sum_{i=1}^{n}x_{i}\left(0\right)$
\end_inset

 using a distributive system dynamics 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathbf{\dot{x}}=F\left(\mathbf{x},\mathbf{u}\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 in a network 
\begin_inset Formula $G$
\end_inset

.
 
\end_layout

\begin_layout Standard
We are interested in the distributive solutions of the consensus problem
 as the network only allows an node to communicate with its neighbors.
 We say the protocol 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:consensus protocol"

\end_inset

 solves the consensus problem asymptotically if and only if there exists
 an asymptotically stable state 
\begin_inset Formula $x^{*}={\cal X}\left(\mathbf{x}\right)$
\end_inset

 of system dynamics 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:system dynamic"

\end_inset

, which satisfying for all 
\begin_inset Formula $\delta>0$
\end_inset

, there exists a time index 
\begin_inset Formula $t^{*}>0$
\end_inset

, such that 
\begin_inset Formula $\left|x_{i}(t)-x^{*}\right|<\delta$
\end_inset

 for all 
\begin_inset Formula $t>t^{*}$
\end_inset

 and 
\begin_inset Formula $\forall i\in{\cal V}$
\end_inset

.
\end_layout

\begin_layout Standard
The average consensus problem is much challenge than the maximum consensus
 (or minimum consensus), since it relates a linear combination of all the
 initial states of network nodes and the condition 
\begin_inset Formula $x_{i}^{*}={\cal X}\left(\mathbf{x}\right)$
\end_inset

 for all nodes 
\begin_inset Formula $i$
\end_inset

 has to be satisfied.
 Furthermore, the variance consensus problem can be solved by two instances
 of average consensus, because we have the relation 
\begin_inset Formula $\mbox{var}\left(\mathbf{x}\right)=\mbox{mean}\left(\mathbf{x}\cdot\mathbf{x}\right)-\left[\mbox{mean}\left(\mathbf{x}\right)\right]^{2}$
\end_inset

.
 Thus, in the following of this thesis we focus on the average consensus
 problem and the distributed average consensus (DAC) algorithms.
 
\end_layout

\begin_layout Subsection
Continuous-time vs.
 Discrete-time Consensus
\end_layout

\begin_layout Standard
In this section, we illustrate consensus protocol 
\begin_inset Formula 
\begin{equation}
u_{i}\left(t\right)=\sum_{j\in{\cal N}_{i}}a_{ij}\left(x_{j}-x_{i}\right)\label{eq:1st Order Protocol}
\end{equation}

\end_inset

that solves the average consensus problem 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula ${\cal X}\left(\mathbf{x}\right)=\mbox{mean}\left(\mathbf{x}\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 and show the difference and similarity of continuous-time with the dynamics
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\dot{x}_{i}\left(t\right)=u_{i}\left(t\right)\label{eq:continuous-time consensus}
\end{equation}

\end_inset

and discrete-time consensus with the dynamics 
\begin_inset Formula 
\begin{equation}
x_{i}\left(k+1\right)=x_{i}\left(k\right)+u_{i}\left(k\right)\label{eq:discre-time consensus}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The continuous-time consensus requires the nodes in a network have dynamics
 in a form of differential equations while nodes in the discrete-time consensus
 has dynamics in difference equation.
 Continuous-time consensus involves analog signals that are easily interfered
 by channel noise.
 Consequently, the finally consensus value will be a random variable with
 mean equals to the consensus value without noise and variance proportional
 to the signal noise ratio.
 It is shown in 
\begin_inset CommandInset citation
LatexCommand cite
key "Kar2009"

\end_inset

, the variance is also proportional to time 
\begin_inset Formula $t$
\end_inset

 hence it is increasing as the algorithm executing.
 
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
Without the channel noise, the system dynamics with the feedback in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:1st Order Protocol"

\end_inset

 can evolve into a linear system with differential equation given by 
\begin_inset Formula 
\begin{equation}
\mathbf{\dot{x}}\left(t\right)=-{\cal L}\mathbf{x}\left(t\right)\label{eq:system differential dynamics}
\end{equation}

\end_inset

Solving the differential equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:system differential dynamics"

\end_inset

 will yield a continuous-time solution in an exponential matrices form 
\begin_inset Formula 
\begin{equation}
\mathbf{x}\left(t\right)=\exp\left(-{\cal L}t\right)\mathbf{x}\left(0\right)\label{eq:x(t) of CT-1st-DAC}
\end{equation}

\end_inset

where 
\begin_inset Formula ${\cal L}$
\end_inset

 is called the weighted graph Laplacian associated with network graph 
\begin_inset Formula ${\cal G}$
\end_inset

, which is defined by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
l_{ij}=\begin{cases}
\sum_{k=1,k\neq i}^{n}a_{ik} & j=i\\
-a_{ij} & j\neq i
\end{cases}\label{eq:Graph Laplacian def.}
\end{equation}

\end_inset

For a graph with 0-1 adjacency, the graph Laplacian can be denoted in another
 form, which is unweighted Laplacian matrix denoted by 
\begin_inset Formula $ L$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
l_{ij}=\begin{cases}
\left|{\cal N}_{i}\right| & j=i\\
-1 & j\in{\cal N}_{i}\\
0 & \mbox{otherwise}
\end{cases}\label{eq:Laplacian def.}
\end{equation}

\end_inset

In some literature for example 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2009a"

\end_inset

, they use the second definition (
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Laplacian def."

\end_inset

) of the Laplacian matrix to analyze the convergence rate of DAC algorithm.
 It is a special case when weights 
\begin_inset Formula $a_{ij}$
\end_inset

 for all edges in 
\begin_inset Formula ${\cal E}$
\end_inset

 equal to one.
 Therefore, to distinguish them, we denote the weighted graph Laplacian
 matrix and the unweighted Laplacian matrix by 
\begin_inset Formula ${\cal L}$
\end_inset

 and 
\begin_inset Formula $ L$
\end_inset

 respectively.
 
\end_layout

\begin_layout Standard
On the other hand, discrete-time consensus only involves the quantization
 error during the algorithm execution as long as the data packages are correctly
 received.
 Nowadays, sensor nodes with digital processing unit becomes more cheaper,
 we can get more benefits from the advantages of discrete-time consensus
 algorithms.
 Consequently, discrete-time consensus algorithms are mainly discussed in
 the following of this thesis.
 
\end_layout

\begin_layout Standard
For network agents have discrete-time consensus protocol, their system dynamics
 can be given in a matrix form
\begin_inset Formula 
\begin{equation}
\mathbf{x}(k+1)= W\mathbf{x}(k)
\end{equation}

\end_inset

where 
\begin_inset Formula $ W=\left[w_{ij}\right]=I-{\cal L}$
\end_inset

.
 We say the iteration is convergent if there exists a vector denoted by
 
\begin_inset Formula $\mathbf{x}^{*}$
\end_inset

, which satisfies.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{x}^{*}= W\mathbf{x}^{*}\label{eq:stable state iteration}
\end{equation}

\end_inset

Moreover, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{x}(k+1)-\mathbf{x}^{*}= W\left[\mathbf{x}(k)-\mathbf{x}^{*}\right]\label{eq:error vector iter. 1st}
\end{equation}

\end_inset


\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:stable state iteration"

\end_inset

 states that 
\begin_inset Formula $\mathbf{x}^{*}$
\end_inset

 is a right eigenvector of matrix 
\begin_inset Formula $ W$
\end_inset

 associated to a simple eigenvalue 1.
 For more details about the discrete-time first-order DAC algorithm, see
 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:DT-First-Order-DAC"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Graph Theory and Matrix Theory
\end_layout

\begin_layout Standard
In this section, some basic concepts of the graph theory and matrix theory
 will be introduced.
 They are used in the analysis of convergence or performance of consensus
 algorithm.
 Because consensus algorithm actually relates to a matrix iteration algorithm,
 it is necessary to introduce some of these theorems.
 For full information about matrix theory, see 
\begin_inset CommandInset citation
LatexCommand cite
key "Varga2010"

\end_inset

, and the work 
\begin_inset CommandInset citation
LatexCommand cite
key "Russell1994"

\end_inset

 states more details about Laplacian matrix.
 However, some useful properties of Laplacian matrix will to be introduced
 here.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula ${\cal G}=\left({\cal V},{\cal E},{\cal A}\right)$
\end_inset

 be a graph with 
\begin_inset Formula $n$
\end_inset

 nodes.
 The in-degree and out-degree of node 
\begin_inset Formula $i$
\end_inset

 are defined by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
D_{in}\left(i\right)=\sum_{i=1}^{n}a_{i,j}
\end{equation}

\end_inset


\begin_inset Formula 
\begin{equation}
D_{out}\left(i\right)=\sum_{j=1}^{n}a_{i,j}
\end{equation}

\end_inset

where 
\begin_inset Formula $a_{i,j}$
\end_inset

 is the elements of matrix 
\begin_inset Formula ${\cal A}$
\end_inset

.
 This definition states that in-degree of node 
\begin_inset Formula $i$
\end_inset

 is the 
\begin_inset Formula $i^{th}$
\end_inset

 column sum of matrix 
\begin_inset Formula ${\cal A}$
\end_inset

 and the out-degree of node 
\begin_inset Formula $i$
\end_inset

 is the 
\begin_inset Formula $i^{th}$
\end_inset

 row sum of matrix 
\begin_inset Formula ${\cal A}.$
\end_inset

 And the graph Laplacian matrix 
\begin_inset Formula ${\cal L}$
\end_inset

 induced by the 
\begin_inset Formula ${\cal G}$
\end_inset

 is the same as defined before, see 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Graph Laplacian def."

\end_inset

.
 In addition, we can find the relationship of 
\begin_inset Formula ${\cal L}$
\end_inset

 and 
\begin_inset Formula ${\cal A}$
\end_inset

.
 
\begin_inset Formula 
\begin{equation}
{\cal L}=\Delta-{\cal A}
\end{equation}

\end_inset

 where 
\begin_inset Formula $\Delta$
\end_inset

 is a diagonal matrix 
\begin_inset Formula $\Delta=\left[\Delta_{i,j}\right]$
\end_inset

, 
\begin_inset Formula $\Delta_{i,j}=0$
\end_inset

 for all 
\begin_inset Formula $i\neq j$
\end_inset

 and 
\begin_inset Formula $\Delta_{ii}=D_{out}\left(i\right)$
\end_inset

.
\end_layout

\begin_layout Standard
Note that we assume the diagonal elements 
\begin_inset Formula $a_{i,i}$
\end_inset

 of matrix 
\begin_inset Formula ${\cal A}$
\end_inset

 equal to zero for all 
\begin_inset Formula $i$
\end_inset

.
 Thus, the Laplacian matrix is only dependent on the off-diagonal elements
 of 
\begin_inset Formula ${\cal A}$
\end_inset

.
 Moreover, if we assume matrix 
\begin_inset Formula ${\cal A}$
\end_inset

 is non-negative, we can benefit from the properties of non-negative matrix,
 and use them in optimization of convergence rate of consensus algorithm.
\end_layout

\begin_layout Subsubsection
Irreducibility and Strong Connected Graph.
\end_layout

\begin_layout Standard
For an undirected graph, the consensus 
\begin_inset Formula $\mathbf{x}^{*}$
\end_inset

 can be achieved if and only if the graph is connected.
 (Note that the consensus is a stable state of the system dynamic.
 For the average consensus problem the consensus state is a state where
 all the network node converge to the global average.) But for the directed
 graph, this condition of achieving consensus becomes into if and only if
 the graph is strongly connected.
 
\end_layout

\begin_layout Standard
A directed graph is strongly connected if and only if for any two distinct
 nodes 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

, there exists a path that follows the direction of the edges and connects
 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

 on the digraph.
 
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "Def.Irreducebility"

\end_inset

for 
\begin_inset Formula $n>1$
\end_inset

, an 
\begin_inset Formula $n\times n$
\end_inset

 matrix 
\begin_inset Formula $A\in R^{n\times n}$
\end_inset

 is reducible if there exists an 
\begin_inset Formula $n\times n$
\end_inset

 permutation matrix 
\begin_inset Formula $P$
\end_inset

 such that 
\begin_inset Formula $PAP^{T}$
\end_inset

 is in block upper triangular form.
 
\begin_inset Formula 
\begin{equation}
PAP^{T}=\left[\begin{array}{cc}
A_{1,1} & A_{1,2,}\\
O & A_{2,2}
\end{array}\right]
\end{equation}

\end_inset

where 
\begin_inset Formula $A_{1,1}$
\end_inset

 is an 
\begin_inset Formula $r\times r$
\end_inset

 submatrix and 
\begin_inset Formula $A_{2,2}$
\end_inset

 is an 
\begin_inset Formula $\left(n-r\right)\times\left(n-r\right)$
\end_inset

 submatrix, and 
\begin_inset Formula $O$
\end_inset

 is an null matrix, 
\begin_inset Formula $1\leq r<n$
\end_inset

.
 If no such a permutation matrix exists, the matrix 
\begin_inset Formula $A$
\end_inset

 is irreducible.
 If 
\begin_inset Formula $n=1$
\end_inset

, then 
\begin_inset Formula $A$
\end_inset

 is reducible if 
\begin_inset Formula $A=0$
\end_inset

, and irreducible otherwise.
 
\end_layout

\begin_layout Standard
The relationship of the irreducible property of matrix 
\begin_inset Formula $A$
\end_inset

 and the strong connected property of directed graph 
\begin_inset Formula ${\cal G}\left(A\right)$
\end_inset

 is stated by the following theorem.
\end_layout

\begin_layout Theorem
An 
\begin_inset Formula $n\times n$
\end_inset

 complex matrix 
\begin_inset Formula $A\in C^{n\times n}$
\end_inset

 is irreducible if and only if its directed graph 
\begin_inset Formula ${\cal G}\left(A\right)$
\end_inset

 is strongly connected.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Varga2010"

\end_inset


\end_layout

\begin_layout Standard
The proof of this theorem is obvious.
 If a graph is strongly connected, all the off diagonal elements of graph
 matrix 
\begin_inset Formula $A$
\end_inset

 cannot be vanished by matrix permutation.
 Therefore, matrix 
\begin_inset Formula $A$
\end_inset

 doesn't exists the block upper triangular form as given in Def.
 
\begin_inset CommandInset ref
LatexCommand formatted
reference "Def.Irreducebility"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Spectral radius of a matrix
\end_layout

\begin_layout Standard
Spectral radius of a matrix is one of the basic concepts in the matrix iteration
 theory.
 It is defined by the largest eigenvalue of the matrix.
 The matrix iteration is very useful in many applications, denoted by 
\begin_inset Formula $A,A^{2},A^{3},\ldots$
\end_inset

.
 The power sequence is said to be convergent, if and only if 
\begin_inset Formula $\lim_{k\to\infty}A^{k}=O$
\end_inset

, where 
\begin_inset Formula $O$
\end_inset

 is a zero matrix with all zero entries.
 The following theorem states that the convergent property is strongly connected
 with the spectral radius.
 
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:Convergent <=> p(A)<1"

\end_inset

 if 
\begin_inset Formula $A\in C^{n\times n}$
\end_inset

 is an 
\begin_inset Formula $n\times n$
\end_inset

 complex matrix, then 
\begin_inset Formula $A$
\end_inset

 is convergent if and only if 
\begin_inset Formula $\rho\left(A\right)<1.$
\end_inset


\end_layout

\begin_layout Standard
The proof of 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:Convergent <=> p(A)<1"

\end_inset

 is not presented here, however it will be very useful in the proof of an
 convergence conditions theorem for distributive consensus algorithm, see
 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:DT-First-Order-DAC"

\end_inset

.
 At the same time the Jordan normal form weight matrix 
\begin_inset Formula $ W^{k}=TJ^{k}T^{-1}$
\end_inset

 gives the local value vector 
\begin_inset Formula $\mathbf{x}\left(k\right)= W^{k}\mathbf{x}\left(0\right)$
\end_inset

 another expression in a form of eigenvalues and eigenvectors, which reflects
 the basic ideas of the finite-time consensus algorithm.
 This will be introduced in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sec:Finite-Time-Distributed-Consensu"

\end_inset

.
 
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Paragraph
Gerschgorin's theorem
\end_layout

\begin_layout Standard
The calculation of eigenvalues a matrix 
\begin_inset Formula $A$
\end_inset

 involves determination of the matrix 
\begin_inset Formula $\lambda I-A$
\end_inset

 and solving a high order polynomial equation.
 In some situations, for example, when the matrix dimension is very large,
 it is very difficult to determine the spectral radius precisely.
 However, the following theorem of Gerschgorin provides an upper bound of
 the spectral radius 
\begin_inset CommandInset citation
LatexCommand cite
key "Horn1990"

\end_inset

.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:Gerschgorin's theorem"

\end_inset

Let 
\begin_inset Formula $A=\left(a_{i,j}\right)$
\end_inset

 be an arbitrary 
\begin_inset Formula $n\times n$
\end_inset

 matrix.
 Denote the 
\begin_inset Formula 
\begin{equation}
d_{i}=\sum_{j=1,j\neq i}^{n}\left|a_{i,j}\right|
\end{equation}

\end_inset

then all the eigenvalues of matrix 
\begin_inset Formula $A$
\end_inset

 are lie in the union of the disks.
\begin_inset Formula 
\begin{equation}
\left|z-a_{i,i}\right|\leq d_{i},\ 1\leq i\leq n.
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Just as we assume before, the adjacent matrix 
\begin_inset Formula ${\cal A}$
\end_inset

 of the graph 
\begin_inset Formula ${\cal G}$
\end_inset

 is non-negative, which means all elements are non-negative.
 Then, the induced graph Laplacian matrix will have the following result
 using the Gerschgorin's theorem.
 
\end_layout

\begin_layout Paragraph
Generalize from Gerschgorin's theorem
\end_layout

\begin_layout Theorem
\begin_inset CommandInset citation
LatexCommand cite
key "Olfati-Saber2004"

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "thm:Bounds of eig(L)"

\end_inset

Let the graph has the Laplacian matrix 
\begin_inset Formula ${\cal L},$
\end_inset

 denote the maximum node outdegree of the graph by 
\begin_inset Formula 
\begin{equation}
d_{max}=\max_{1\leq i\leq n}\left(\sum_{j=1,j\neq i}^{n}l_{i,j}\right)
\end{equation}

\end_inset

Then, all the eigenvalues of 
\begin_inset Formula ${\cal L}$
\end_inset

 are located in the following disk,
\begin_inset Formula 
\begin{equation}
\left|z-d_{max}\right|\leq d_{max}
\end{equation}

\end_inset

which is centered at 
\begin_inset Formula $z=d_{max}+0j$
\end_inset

 on the complex plane.
\end_layout

\begin_layout Proof
Based on the Gerschgorin's theorem, all the eigenvalue of 
\begin_inset Formula ${\cal L}$
\end_inset

 are located in the union of the disks.
\begin_inset Formula 
\begin{equation}
\left|z-l_{i,i}\right|\leq\sum_{j=1,j\neq i}^{n}\left|l_{i,j}\right|,\ 1\leq i\leq n.\label{eq:disk Union of eig(L)}
\end{equation}

\end_inset

Since 
\begin_inset Formula ${\cal A}=\left[a_{i,j}\right]$
\end_inset

 is an non-negative matrix, by the definition of Laplacian matrix, 
\begin_inset Formula $l_{i,j}\leq0$
\end_inset

 and 
\begin_inset Formula $l_{i,i}=\sum_{k=1,k\neq i}^{n}a_{ik}\geq0.$
\end_inset

 Therefore, let 
\begin_inset Formula $d_{i}=l_{i,i}$
\end_inset

 and 
\begin_inset Formula 
\begin{equation}
d_{i}=\sum_{j=1,j\neq i}^{n}\left|l_{i,j}\right|
\end{equation}

\end_inset

 and the union of disks becomes
\begin_inset Formula 
\begin{equation}
\bigcup_{1\leq i\leq n}\left\{ z\in\mathbb{C}:\left|z-d_{i}\right|\leq d_{i}\right\} 
\end{equation}

\end_inset

On the other hand, all these disks are located inside the largest disk with
 radius 
\begin_inset Formula $d_{max}$
\end_inset

.
 This result ends the proof of the theorem
\end_layout

\begin_layout Standard
Based on the 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:Bounds of eig(L)"

\end_inset

, it is obvious all the nonzero eigenvalues of 
\begin_inset Formula ${\cal L}$
\end_inset

 have positive real parts.
 This immediately lead to a convergence theorem of the continuous-time consensus
 protocol 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:1st Order Protocol"

\end_inset

.
 The solution given in exponential matrices form 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:x(t) of CT-1st-DAC"

\end_inset

 converge to a consensus value as 
\begin_inset Formula $t\to\infty$
\end_inset

.
 Since all the nonzero eigenvalue of 
\begin_inset Formula $-{\cal L}$
\end_inset

 located in the disk 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\left|z+d_{max}\right|\leq d_{max}$
\end_inset

, and the eigenspace associated with zero is one-dimensional.
 Consequently, the eigenvector associated with zero eigenvalue has the form
 
\begin_inset Formula $\alpha\mathbf{1}$
\end_inset

, i.e.
 
\begin_inset Formula $x_{i}=\alpha$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

.
 This result will be very helpful as the negative real part can guarantee
 that the system dynamic is stable and convergent.
 We will show the proof after introduce the well-known Perron-Frobenius
 Theorem.
 
\end_layout

\begin_layout Paragraph
Perron-Frobenius Theorem
\end_layout

\begin_layout Standard
The Perron-Frobenius theorem states that if matrix 
\begin_inset Formula $A$
\end_inset

 is nonnegative and irreducible which means the digraph of matrix A is strongly
 connected, the spectral radius 
\begin_inset Formula $\rho(A)$
\end_inset

 is equal to a simple eigenvalue of 
\begin_inset Formula $A$
\end_inset

 associated with a positive eigenvector 
\begin_inset CommandInset citation
LatexCommand cite
key "Piziak2007"

\end_inset

.
 The details of Perron-Frobenius is as follows.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:Perron-Frobenius thm."

\end_inset

 Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 and irreducible matrix with non-negative and real numbers as its entries.
 Then, 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $A$
\end_inset

 has a positive real eigenvalue equal to its spectral radius 
\begin_inset Formula $\rho\left(A\right)$
\end_inset

.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\rho\left(A\right)$
\end_inset

 is a simple eigenvalue of 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Enumerate
To the eigenvalue 
\begin_inset Formula $\rho\left(A\right)$
\end_inset

, the corresponding eigenvector is positive, i.e.
 
\begin_inset Formula $\mathbf{x}>\mathbf{0}$
\end_inset

.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\rho\left(A\right)$
\end_inset

 increases if any entry of 
\begin_inset Formula $A$
\end_inset

 increases.
\end_layout

\begin_layout Standard
Recall the problem of finding the bounds for the spectral radius, the Perron-Fro
benius theorem provides the nontrivial lower-bound of 
\begin_inset Formula $\rho\left(A\right)$
\end_inset

.
 In the 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:Gerschgorin's theorem"

\end_inset

, the nontrivial upper bound of 
\begin_inset Formula $\rho\left(A\right)$
\end_inset

 is found.
 Together with these two results, we can have a conclusion of the spectral
 radius of a non-negative and irreducible matrix given in the following.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $A=\left[a_{i,j}\right]$
\end_inset

 is an 
\begin_inset Formula $n\times n$
\end_inset

 non-negative and irreducible matrix, then for any 
\begin_inset Formula $\mathbf{x}>\mathbf{0}$
\end_inset

, either
\begin_inset Formula 
\begin{equation}
\min_{1\leq i\leq n}\left(\frac{\sum_{j=1}^{n}a_{i,j}x_{j}}{x_{i}}\right)<\rho\left(A\right)<\max_{1\leq i\leq n}\left(\frac{\sum_{j=1}^{n}a_{i,j}x_{j}}{x_{i}}\right)
\end{equation}

\end_inset

or 
\begin_inset Formula 
\begin{equation}
\frac{\sum_{j=1}^{n}a_{i,j}x_{j}}{x_{i}}=\rho\left(A\right),\ \mbox{for all }1\leq i\leq n.
\end{equation}

\end_inset

Moreover,
\begin_inset Formula 
\begin{equation}
\max_{\mathbf{x}\in P}\min_{1\leq i\leq n}\left(\frac{\sum_{j=1}^{n}a_{i,j}x_{j}}{x_{i}}\right)=\rho\left(A\right)=\min_{\mathbf{x}\in P}\max_{1\leq i\leq n}\left(\frac{\sum_{j=1}^{n}a_{i,j}x_{j}}{x_{i}}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The equality is valid if we choose the 
\begin_inset Formula $\mathbf{x}$
\end_inset

 equal to the positive eigenvector 
\begin_inset Formula $e>0$
\end_inset

 corresponding to the eigenvalue 
\begin_inset Formula $\rho\left(A\right)$
\end_inset

.
 The method shown above will be applicable, because it provides us both
 the upper bounds and lower bounds for the spectral radius of a non-negative
 and irreducible matrix, by a simple algorithm without calculating the determina
tion of 
\begin_inset Formula $\lambda I-A$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Generalized from Perron-Frobenius theorem
\end_layout

\begin_layout Standard
The result induced from Perron-Frobenius theorem gives the upper bound and
 lower bound of the matrix.
 Considering the system dynamic 
\begin_inset Formula $x\left(t\right)=\exp\left(-{\cal L}t\right)x\left(0\right)$
\end_inset

.
 Because 
\begin_inset Formula $\exp\left(-{\cal L}t\right)$
\end_inset

 is a non-negative matrix, the Perron-Frobenius theorem tell us that 
\begin_inset Formula $\exp\left(-{\cal L}t\right)$
\end_inset

 has a positive real eigenvalue equals to one which is also the spectral
 radius.
 Together with the 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:Bounds of eig(L)"

\end_inset

 which implies that all the eigenvalues of 
\begin_inset Formula $-{\cal L}$
\end_inset

 have negative real part, we immediately come to the following theorem.
\end_layout

\begin_layout Theorem
Assume 
\begin_inset Formula ${\cal G}=\left({\cal V},{\cal E},{\cal A}\right)$
\end_inset

 is strongly connected graph, and the associated graph Laplacian matrix
 
\begin_inset Formula ${\cal L}$
\end_inset

 is defined in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Graph Laplacian def."

\end_inset

, which has only one zero eigenvalue.
 Let the 
\begin_inset Formula $u_{r}$
\end_inset

 is the uniformed right eigenvector and 
\begin_inset Formula $u_{l}$
\end_inset

 is the uniformed left eigenvector associated with the zero eigenvalue,
 i.e.
 
\begin_inset Formula $Lu_{r}=0$
\end_inset

, 
\begin_inset Formula $u_{l}^{T}L=0$
\end_inset

, then we have 
\begin_inset Formula $u_{l}^{T}u_{r}=1$
\end_inset

 and the system dynamic 
\begin_inset Formula 
\begin{equation}
x\left(t\right)=\exp\left(-{\cal L}t\right)x\left(0\right)
\end{equation}

\end_inset

will have the stable state of the system dynamic given by
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
x\left(t\right)=Kx\left(0\right)
\end{equation}

\end_inset

 where K is a matrix in 
\begin_inset Formula $R^{n}$
\end_inset

, and 
\begin_inset Formula $K=\lim_{t\to\infty}\exp\left(-{\cal L}t\right)=u_{r}u_{l}^{T}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A=-{\cal L}$
\end_inset

, and it has a Jordan form of 
\begin_inset Formula $A=UJU^{-1}$
\end_inset

.
 Then we can have 
\begin_inset Formula $\exp\left(At\right)=U\exp\left(Jt\right)U^{-1}$
\end_inset

.
 Because 
\begin_inset Formula $A$
\end_inset

 has all its eigenvalue except a simple zero eigenvalue have negative real
 part, thus, as 
\begin_inset Formula $t\to\infty$
\end_inset

, all other Jordan block vanish, and 
\begin_inset Formula $\exp\left(Jt\right)$
\end_inset

 converges to a matrix with only single nonzero entry, denoted by 
\begin_inset Formula $Q$
\end_inset

.
 Since matrix 
\begin_inset Formula $U$
\end_inset

 contains a column which associated with the zero eigenvalue of 
\begin_inset Formula $A$
\end_inset

 is 
\begin_inset Formula $u_{r}$
\end_inset

, similarly, 
\begin_inset Formula $U^{-1}$
\end_inset

 has a corresponding row equals to 
\begin_inset Formula $u_{l}$
\end_inset

.
 By simply calculating the equation 
\begin_inset Formula $K=UQU^{-1}$
\end_inset

, we can show that 
\begin_inset Formula $K=u_{r}u_{l}^{T}$
\end_inset

.
 And the fact 
\begin_inset Formula $U^{-1}U=I$
\end_inset

 shows that 
\begin_inset Formula $u_{l}^{T}u_{r}=1$
\end_inset

 .
 This ends the proof.
 
\end_layout

\begin_layout Standard
This is an important theory for continuous-time consensus problem.
 It provides the necessary and sufficient conditions of the graph Laplacian
 matrix so that a convergent consensus algorithm could be carried out on
 the network.
 For the average consensus problem, it is obvious that all the elements
 in 
\begin_inset Formula $K$
\end_inset

 must equal to 
\begin_inset Formula $\frac{1}{n}$
\end_inset

.
 This requires the graph Laplacian 
\begin_inset Formula ${\cal L}$
\end_inset

 satisfies the conditions: 
\begin_inset Formula ${\cal L}\mathbf{1}=0$
\end_inset

, 
\begin_inset Formula $\mathbf{1}^{T}{\cal L}=0$
\end_inset

, where 
\begin_inset Formula $\mathbf{1}\in R^{n}$
\end_inset

 is an all unity vector.
 And the 
\begin_inset Formula $u_{r}$
\end_inset

 and 
\begin_inset Formula $u_{l}$
\end_inset

 will change into vectors with equivalent constant in all its components.
 If they are uniformed, then 
\begin_inset Formula $u_{r}=u_{l}=\frac{1}{\sqrt{n}}.$
\end_inset

 
\end_layout

\begin_layout Subsubsection
Diagonalizable matrix & Symmetric matrix
\end_layout

\begin_layout Standard
The Jordan normal form of weight matrix 
\begin_inset Formula $ W^{k}=TJ^{k}T^{-1}$
\end_inset

 gives the local value vector 
\begin_inset Formula $\mathbf{x}\left(k\right)= W^{k}\mathbf{x}\left(0\right)$
\end_inset

 an analytical expression in terms of eigenvalues and eigenvectors.
 Moreover, if the matrix 
\begin_inset Formula $ W$
\end_inset

 is symmetric, the expressions of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathbf{x}\left(k\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 can be simplified.
 Then, algorithms such as the finite-time consensus, can be implemented
 more easily.
 In addition, under the the assumption of symmetric weight matrices, the
 optimal weight matrix which has the fastest convergence rate can be found
 through a semi-definite problem.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Li2010"

\end_inset

.
 
\end_layout

\begin_layout Definition
A matrix 
\begin_inset Formula $A$
\end_inset

 is diagonalized, if and only if there exist a nonsingular matrix 
\begin_inset Formula $T$
\end_inset

, which reduce 
\begin_inset Formula $A$
\end_inset

 into the form 
\begin_inset Formula 
\[
T^{-1}AT=\mbox{diag}\left(\lambda_{1},\lambda_{2},\ldots,\lambda_{n}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Generally, a matrix are diagonalized by an unitary matrix if and only if
 it is normal.
 Normal matrix 
\begin_inset Formula $A$
\end_inset

 means it satisfies 
\begin_inset Formula $A^{H}A=AA^{H}$
\end_inset

.
 Let 
\begin_inset Formula $\lambda_{1},\lambda_{2},\ldots,\lambda_{n}$
\end_inset

 be the eigenvalues of 
\begin_inset Formula $A$
\end_inset

.
 There exists an u
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
nitary matrix 
\begin_inset Formula $U$
\end_inset

, which 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
satisfies
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $U^{H}=U^{-1}$
\end_inset

, such that 
\begin_inset Formula $U^{-1}AU=\mbox{diag}\left(\lambda_{1},\lambda_{2},\ldots,\lambda_{n}\right)$
\end_inset

.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
For real normal matrix 
\begin_inset Formula $A$
\end_inset

, if all of its eigenvalues are real, there exists an orthogonal matrix
 
\begin_inset Formula $P,$
\end_inset

 which has 
\begin_inset Formula $P^{T}=P^{-1}$
\end_inset

, reduces the real matrix 
\begin_inset Formula $A$
\end_inset

 into diagonalized form 
\begin_inset Formula $P^{-1}AP=\mbox{diag}\left(\lambda_{1},\lambda_{2},\ldots,\lambda_{n}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Specifically, any real nonsingular symmetric matrix 
\begin_inset Formula $A\in R^{n\times n}$
\end_inset

 has 
\begin_inset Formula $n$
\end_inset

 linearly independent real eigenvectors.
 Moreover, these eigenvectors can be chosen so that they are orthogonal
 to each other with modular one.
 Thus, the real symmetric matrix can be decomposed by an orthogonal matrix
 
\begin_inset Formula $P$
\end_inset

, i.e.
 
\begin_inset Formula $A=P\Lambda P^{-1}$
\end_inset

, where 
\begin_inset Formula $\Lambda$
\end_inset

 is a diagonal matrix whose entries equal to the eigenvalues of 
\begin_inset Formula $A$
\end_inset

.
 Also the symmetric matrix has all its eigenvalues algebra multiplicity
 equal to the geometric multiplicity, and all the Jordan block have size
 one.
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Asymptotic Distributed Consensus Algorithm
\end_layout

\begin_layout Standard
The averaging consensus problem can be solved not only by DAC algorithms,
 but also in many other ways, such as flooding, gossip and so on.
 In the flooding algorithm, each sensor maintains a table of all sensors
 values which initialize by its local value.
 At each iteration of the flooding algorithm, every node exchanges the table
 with their neighbors.
 After enough steps, which is larger than the diameter of the network.
 Every node will get all the initial value of all nodes.
 Gossip algorithms are asynchronous.
 Only one random node wakes up and randomly chooses another node.
 The two nodes exchange their estimates and update to the average of the
 two.
 
\end_layout

\begin_layout Standard
Due to the simplicity and robustness of asymptotic distributed consensus
 algorithm, it plays an important role in the practical problems.
 They are already applied to network with a large number of nodes and proofed
 to be robust against the topology variation.
 Once the network graph is strong connected, the convergence to global consensus
 value is guaranteed 
\begin_inset CommandInset citation
LatexCommand cite
key "Ren2007"

\end_inset

.
 In this section, we start from the first-order DAC algorithm and then expand
 the algorithm to higher-order in order to yields a higher the convergence
 rate.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:DT-First-Order-DAC"

\end_inset

Discrete First Order Distributed Consensus Algorithm
\end_layout

\begin_layout Standard
First Order Distributed Consensus Algorithm (FO-DCA) is an algorithm that
 update the local value of node 
\begin_inset Formula $i$
\end_inset

 iteratively at each time-step 
\begin_inset Formula $k$
\end_inset

, based on node’s previous values one time step before, given by Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:1st iter. ni"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
x_{i}(k+1) & = & x_{i}(k)+\sum_{j\in\mathcal{N}_{i}}w_{ij}\left[x_{j}(k)-x_{i}(k)\right]\label{eq:1st iter. ni}\\
 & = & w_{ii}x_{i}(k)+\sum_{j\in\mathcal{N}_{i}}w_{ij}x_{j}(k)
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $k=0,1,2,...$
\end_inset

 is the time index, 
\begin_inset Formula $w_{ij}$
\end_inset

 is the weight to 
\begin_inset Formula $x_{j}$
\end_inset

 at node 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $w_{ij}=0$
\end_inset

 if 
\begin_inset Formula $(i,j)\notin\mathcal{E}$
\end_inset

.
 Note that we define a weight to node 
\begin_inset Formula $i$
\end_inset

 itself 
\begin_inset Formula $w_{ii}=1-\sum_{j\in\mathcal{N}_{i}}w_{ij}$
\end_inset

, so that the sum of all weights equals to one, 
\begin_inset Formula $\sum_{j=1}^{n}w_{ij}=1$
\end_inset

.
 
\end_layout

\begin_layout Standard
The iteration 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:1st iter. ni"

\end_inset

 can be written in a vector form 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{x}(k+1)= W\mathbf{x}(k)\label{eq:first order matrix}
\end{equation}

\end_inset

where 
\begin_inset Formula $ W$
\end_inset

 is a weight matrix which refer to as the Perron matrix induced by 
\begin_inset Formula ${\cal G}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Olfati-Saber2004"

\end_inset

.
 This linear iteration implies that 
\begin_inset Formula $\mathbf{x}(k)= W^{k}\mathbf{x}(0)$
\end_inset

 for 
\begin_inset Formula $k=1,2,\cdots$
\end_inset

.
 
\end_layout

\begin_layout Standard
Since the initial value vector is randomly chosen, the matrix 
\begin_inset Formula $ W$
\end_inset

 must satisfy some convergence conditions to make sure the iteration convergent,
 and the convergence rate depends on the spectral radius of matrix 
\begin_inset Formula $ W$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Convergence Conditions
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
For the matrix iteration defined in Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:first order matrix"

\end_inset

, the average consensus problem is to choose the weight matrix 
\begin_inset Formula $ W$
\end_inset

, so that for any initial value 
\begin_inset Formula $\mathbf{x}(0)\in R^{n}$
\end_inset

, 
\begin_inset Formula $\mathbf{x}(k)$
\end_inset

 converges to the vector 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{\bar{x}}=\left(\mathbf{1}^{\mathrm{T}}\mathbf{x}(0)/n\right)\mathbf{1}=\dfrac{\mathbf{11}^{\mathrm{T}}}{n}\mathbf{x}(0)
\end{equation}

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset CommandInset label
LatexCommand label
name "thm:convergence condition"

\end_inset


\begin_inset Formula $\lim_{k\rightarrow\infty}\mathbf{x}(k)=\mathbf{\bar{x}}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 if and only if the matrix 
\begin_inset Formula $ W$
\end_inset

 satisfie
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
s
\begin_inset Formula 
\begin{equation}
\lim_{k\rightarrow\infty} W^{k}=\dfrac{\mathbf{11}^{\mathrm{T}}}{n}.\label{eq:convege condition W}
\end{equation}

\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:convege condition W"

\end_inset

 holds if and only if
\begin_inset Formula 
\begin{eqnarray}
\mathbf{1}^{\mathrm{T}} W & = & \mathbf{1}^{\mathrm{T}}\label{eq: Converge condition W_Left}\\
 W\mathbf{1} & = & \mathbf{1}\label{eq: Converge condition W_right}\\
\rho\left( W-\mathbf{11}^{\mathrm{T}}/n\right) & < & 1\label{eq:Converge cond. rhu<1}
\end{eqnarray}

\end_inset

where vector 
\begin_inset Formula $\mathbf{1}=[1,1,\cdots1,]^{\mathrm{T}}\in R^{n}$
\end_inset

, 
\begin_inset Formula $\rho\left(\cdot\right)$
\end_inset

 denotes the spectral radius of the matrix .
\end_layout

\begin_layout Standard
Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: Converge condition W_Left"

\end_inset

 means that has a left eigenvector 
\begin_inset Formula $\mathbf{1}$
\end_inset

 associated with the eigenvalue 1.
 This implies that the sum of local value vector is not changed in the iteration
 
\begin_inset Formula $\sum_{i\in\mathcal{V}}x_{i}\left(k+1\right)=\sum_{i\in\mathcal{V}}x_{i}\left(k\right)$
\end_inset

 and the sum of each column of matrix 
\begin_inset Formula $ W$
\end_inset

 is equal to one.
 Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: Converge condition W_right"

\end_inset

 shows that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $ W$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 is a row stochastic matrix and has an eigenvalue 1 with associated eigenvector
 
\begin_inset Formula $\mathbf{1}$
\end_inset

.
 Both 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: Converge condition W_Left"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: Converge condition W_right"

\end_inset

 together with the convergence condition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Converge cond. rhu<1"

\end_inset

 means that 
\begin_inset Formula $ W$
\end_inset

 have a simple eigenvalue equals to one, and modular of all other eigenvalues
 are less than one.
\end_layout

\begin_layout Lemma

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset CommandInset label
LatexCommand label
name "thm:Share the eigenvalues"

\end_inset

If 
\begin_inset Formula $\lim_{k\rightarrow\infty} W^{k}=\dfrac{\mathbf{11}^{\mathrm{T}}}{n}$
\end_inset

, the matrix 
\begin_inset Formula $ W-\mathbf{11}^{\mathrm{T}}/n$
\end_inset

 share the same eigenvalues as matrix 
\begin_inset Formula $ W$
\end_inset

 except the simple eigenvalue one is replaced by zero.
\end_layout

\begin_layout Proof
Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq: Converge condition W_Left"

\end_inset

 implies that the matrix 
\begin_inset Formula $ W$
\end_inset

 has a left eigenvector 
\begin_inset Formula $\mathbf{1}$
\end_inset

 associated to eigenvalue one.
 And Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq: Converge condition W_right"

\end_inset

 implies that 
\begin_inset Formula $\mathbf{1}$
\end_inset

 is a right eigenvector of 
\begin_inset Formula $ W$
\end_inset

 associated to eigenvalue one.
 The fact that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\lim_{k\rightarrow\infty} W^{k}=\dfrac{\mathbf{11}^{\mathrm{T}}}{n}$
\end_inset

 exists if and only if there exists a  matrix 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $ W$
\end_inset

 can be Jordan decomposition as 
\begin_inset Formula 
\begin{equation}
 W=U\left[\begin{array}{cccc}
J_{1}\\
 & J_{2}\\
 &  & \ddots\\
 &  &  & J_{m}
\end{array}\right]U^{-1}
\end{equation}

\end_inset

where 
\begin_inset Formula $m$
\end_inset

 is the number of distinct Jordan block.
 
\begin_inset Formula $J_{i}$
\end_inset

 is the 
\begin_inset Formula $r_{i}$
\end_inset

 dimensional Jordan block corresponding to eigenvalue 
\begin_inset Formula $\lambda_{i}$
\end_inset

, 
\begin_inset Formula $J_{1}=I_{r_{1}}$
\end_inset

 is the 
\begin_inset Formula $r_{i}$
\end_inset

 dimensional identity matrix 
\begin_inset Formula $\left(0\leq r_{i}\leq n\right)$
\end_inset

 and all other Jordan block are convergent, i.e.
 
\begin_inset Formula $\rho\left(J_{i}\right)<1,2\leq i\leq m$
\end_inset

.
\end_layout

\begin_layout Proof

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
Let 
\begin_inset Formula $u_{1},u_{2},\ldots,u_{n}$
\end_inset

 be the column of 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $v_{1}^{T},v_{2}^{T},\ldots,v_{n}^{T}$
\end_inset

 be row of 
\begin_inset Formula $U^{-1}$
\end_inset

.
 Then we have 
\begin_inset Formula 
\begin{eqnarray}
\lim_{k\to\infty} W^{k} & = & U\left[\begin{array}{cc}
I_{r_{1}} & 0\\
0 & 0
\end{array}\right]U^{-1}\label{eq: W^k to infinity has Rank one}\\
 & = & \sum_{i=1}^{r_{1}}u_{i}v_{i}^{T}=\dfrac{\mathbf{11}^{\mathrm{T}}}{n}\label{eq:u*v=11}
\end{eqnarray}

\end_inset

As the property of unitary matrix 
\begin_inset Formula $U$
\end_inset

, both 
\begin_inset Formula $u_{i}$
\end_inset

 and 
\begin_inset Formula $v_{i}$
\end_inset

 are set of orthogonal normal vectors, each 
\begin_inset Formula $u_{i}v_{i}^{T}$
\end_inset

 is a matrix with rank one and matrix 
\begin_inset Formula $\sum_{i=1}^{n}u_{i}v_{i}^{T}$
\end_inset

 has rank 
\begin_inset Formula $n$
\end_inset

.
 The sum 
\begin_inset Formula $\sum_{i=1}^{r_{1}}u_{i}v_{i}^{T}$
\end_inset

 must have rank 
\begin_inset Formula $r_{1}.$
\end_inset

 Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:u*v=11"

\end_inset

 shows that 
\begin_inset Formula $r_{1}$
\end_inset

 must equal to one and 
\begin_inset Formula $u_{i}v_{i}^{T}=\dfrac{\mathbf{11}^{\mathrm{T}}}{n}$
\end_inset

, both 
\begin_inset Formula $u_{i}$
\end_inset

 and 
\begin_inset Formula $v_{i}$
\end_inset

 are vectors with the same constant on all components.
 Therefore, 
\begin_inset Formula $ W-\dfrac{\mathbf{11}^{\mathrm{T}}}{n}$
\end_inset

 have the same Jordan decomposition as 
\begin_inset Formula $ W$
\end_inset

 except the Jordan block 
\begin_inset Formula $J_{1}$
\end_inset

 is replaced by zero, and all other Jordan block remain the same.
 This completes the proof.
 
\end_layout

\begin_layout Subsubsection
Find Convergent Weight Matrix for First Order DAC
\end_layout

\begin_layout Standard
The convergence rate of the FO-DCA is related to the spectral radius of
 matrix 
\begin_inset Formula $ W-\dfrac{\mathbf{11}^{\mathrm{T}}}{n}$
\end_inset

.
 To get the maximum convergence rate, an optimization problem to minimize
 the spectral radius of the matrix could be solved 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{array}{ccc}
\mbox{\mbox{Minimize }} & \rho\left( W-\frac{\mathbf{1}\mathbf{1}^{T}}{n}\right)\\
\mbox{Subject to } & \mathbf{1}^{\mathrm{T}} W=\mathbf{1}^{\mathrm{T}},\; W\mathbf{1}=\mathbf{1} & ,
\end{array}\label{eq: Opt. FO-DAC Problem}
\end{equation}

\end_inset

But it requires knowledge of network topology to solve the problem.
 However, some non-optimal convergent weight matrices that satisfy the condition
 in Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:convege condition W"

\end_inset

 are given below.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $ W=\left[w_{i,j}\right],i,j=1,\ldots,n$
\end_inset

, the first one is the constant based weight matrix,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
w_{ij}=\begin{cases}
\epsilon, & \mbox{if }(i,j)\in\mathit{\mathcal{E}}\\
1-d(i)\epsilon, & i=j\\
0, & \mbox{otherwise}
\end{cases}\label{eq:Best Const. Mtx}
\end{equation}

\end_inset

where 
\begin_inset Formula $\epsilon$
\end_inset

 is the step size for the iteration, 
\begin_inset Formula $d(i)$
\end_inset

 is the degree of the node 
\begin_inset Formula $i$
\end_inset

.
 And the weight matrix can be given in an expression involves the Laplacian
 matrix, 
\begin_inset Formula $ W=I-\epsilon L$
\end_inset

.
 
\end_layout

\begin_layout Standard
The FO-DAC algorithm that uses best constant weight matrix 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Best Const. Mtx"

\end_inset

 is called the best constant first-order DAC algorithm (BC FO-DAC).
 
\end_layout

\begin_layout Standard
Substitute this best constant weight matrix into 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq: Opt. FO-DAC Problem"

\end_inset

, the step size that solves the problem is obtained when the eigenvalues
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\lambda_{2}\left(L\right)$
\end_inset

 and
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\begin_inset Formula $\lambda_{n}\left(L\right)$
\end_inset

 of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
Laplacian matrix
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 are available, given by 
\begin_inset Formula $\epsilon=2/\left(\lambda_{2}\left(L\right)+\lambda_{n}\left(L\right)\right)$
\end_inset

, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
where 
\begin_inset Formula $\lambda_{i}\left(L\right)$
\end_inset

 is the 
\begin_inset Formula $i^{th}$
\end_inset

 smallest eigenvalue of Laplacian matrix.
 
\end_layout

\begin_layout Standard
Another option is Metropolis weight matrix (or local degree weight matrix),
 where each weight is determined by degree of the two nodes on the edge,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
w_{ij}=\begin{cases}
\frac{1}{1+\max\left\{ d(i),d(j)\right\} }, & \mbox{if }(i,j)\in\mathit{\mathcal{E}}\\
1-\sum_{(i,k)\in\mathit{\mathcal{E}}}w_{ik}, & i=j\\
0, & \mbox{otherwise}
\end{cases}
\end{equation}

\end_inset

where 
\begin_inset Formula $d(i)$
\end_inset

 and 
\begin_inset Formula $d(j)$
\end_inset

 are the degrees of nodes 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

.
 
\end_layout

\begin_layout Standard
As shown above, the conventional DAC algorithm is depends on 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
eigenvalues of graph Laplacian matrix 
\begin_inset Formula $\lambda_{i}\left(L\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 or degree of nodes.
 However, in the section 
\begin_inset CommandInset ref
LatexCommand eqref
reference "sub:Find-the-Consensus"

\end_inset

, we will show that the finite-time DAC algorithm in an invariant network
 doesn't require these prior knowledge, if 
\begin_inset Formula $\mathbf{x}\left(k\right)$
\end_inset

 can be represented by a linear combination of a new normal basis defined
 by eigenvectors of 
\begin_inset Formula $ W$
\end_inset

.
 Thus, the weight matrix doesn't have too much requirements and can be more
 easily chosen.
 This would be very applicable because nodes in a distributive network usually
 doesn't have any knowledge of network topology.
 
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Discrete-High-Order"

\end_inset

Discrete High Order Distributed Consensus Algorithm 
\end_layout

\begin_layout Standard
Higher order Distributed Consensus Algorithm (HO-DCA) can have faster convergenc
e rate and potentially faster than FO-DCA.
 It can be easily implemented by storing and using past data, and doesn't
 require additional communication and network configuration.
 Moreover, HO-DAC can be regard as a generalized form of distributed consensus
 algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2010"

\end_inset

.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2010"

\end_inset

, the author assume all node can store and using past data and define a
 topology-dependent matrix to update the initial data.
 It involves more parameters than FO-DAC so that the optimization problem
 has more degrees of freedom.
 When some parameters are set to zero, the HO-DCA algorithm can reduce to
 the best constant FO-DAC algorithm.
\end_layout

\begin_layout Standard
Since the convergence rate of the initial values is related to eigenvalues
 of Laplacian matrix.
 In the optimization problem of HO-DCA, eigenvalues of the associated graph
 Laplacian matrix or weight matrix must known.
 
\end_layout

\begin_layout Standard
In a time-invariant, connected network, the 
\begin_inset Formula $M-th$
\end_inset

 high-order DAC algorithm has the form:
\begin_inset Formula 
\begin{eqnarray}
x_{i}(k) & = & x_{i}(k-1)-\epsilon\sum_{m=1}^{M}c_{m}(-\gamma)^{m-1}\Delta x_{i}(k,m),\label{eq:Iteration Second order x_i(k)}\\
\Delta x_{i}(k,m) & = & \sum_{j\in\mathcal{N}_{i}}\left(x_{i}\left(k-m\right)-x_{j}\left(k-m\right)\right),
\end{eqnarray}

\end_inset

Where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $x_{i}(k)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 is the local value at node 
\begin_inset Formula $i$
\end_inset

 during iteration 
\begin_inset Formula $k$
\end_inset

; 
\begin_inset Formula $\mathcal{N}_{i}$
\end_inset

 is the neighboring nodes set in which the nodes can communicate reliably
 with node 
\begin_inset Formula $i$
\end_inset

; 
\begin_inset Formula $\epsilon$
\end_inset

 is a constant step size; 
\begin_inset Formula $M$
\end_inset

 is the highest order number; 
\begin_inset Formula $c_{m}$
\end_inset

 are predefined constants, where 
\begin_inset Formula $c_{1}=1$
\end_inset

 and 
\begin_inset Formula $c_{m}\neq0\:(m>1)$
\end_inset

; 
\begin_inset Formula $\gamma$
\end_inset

 is a forgetting factor, such that 
\begin_inset Formula $\left|\gamma\right|<1$
\end_inset

.
 
\end_layout

\begin_layout Standard
Define
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{x}(k)=\left[x_{1}(k),x_{1}(k),\ldots,x_{n}(k)\right]^{T}
\end{equation}

\end_inset

The Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Iteration Second order x_i(k)"

\end_inset

 can be written in matrix form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{x}(k)=( I_{n}-\epsilon L)\mathbf{x}(k-1)-\epsilon\sum_{m=2}^{M}c_{m}(-\gamma)^{m-1} L\mathbf{x}(k-m)\label{eq:High Order Iter.Vec}
\end{equation}

\end_inset

where 
\begin_inset Formula $ L$
\end_inset

 is the Laplacian matrix associated to the network graph.
 assume 
\begin_inset Formula $\forall k<0,\;\mathbf{x}(k)=\mathbf{x}(0)$
\end_inset

, 
\begin_inset Formula $\mathbf{x}(0)$
\end_inset

 is the initial local state information for node 
\begin_inset Formula $i$
\end_inset

.
 The matrix form states that when the forgetting factor 
\begin_inset Formula $\gamma$
\end_inset

 is set to zero, the HO-DAC is reduced into the best constant FO-DAC algorithm
 given in 
\end_layout

\begin_layout Standard
Simulation result shows that, a higher order will have better convergence
 rate, but should be trade off with the algorithm complexity and computational
 cost.
 Also only a few improvement could be achieved if we introduce larger than
 fourth order.
 
\end_layout

\begin_layout Subsubsection
Convergence Rate Maximization Problem For HO-DAC
\end_layout

\begin_layout Standard
Based on the iteration equation 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:High Order Iter.Vec"

\end_inset

, the 
\begin_inset Formula $M-th$
\end_inset

 high-order DAC algorithm in a time-invariant, connected and undirected
 network, with initial local value vectors 
\begin_inset Formula $\mathbf{x}(-M+1)=,\ldots,=\mathbf{x}(-1)=\mathbf{x}(0)$
\end_inset

, can be further defined by an 
\begin_inset Formula $Mn\times Mn$
\end_inset

 matrices
\begin_inset Formula 
\begin{equation}
\mathbf{H}=\left[\begin{array}{cccc}
 I_{n}-\epsilon L & c_{2}\gamma\epsilon L & \cdots & -c_{M}(-\gamma)^{M-1}\epsilon L\\
 I_{n} & \mathbf{0}_{n\times n} & \cdots & \mathbf{0}_{n\times n}\\
\vdots & \ddots &  & \vdots\\
\mathbf{0}_{n\times n} & \cdots &  I_{n} & \mathbf{0}_{n\times n}
\end{array}\right]
\end{equation}

\end_inset


\begin_inset Formula 
\begin{equation}
\mathbf{J}=\left[\begin{array}{cccc}
\mathbf{K} & \mathbf{0}_{n\times n} & \cdots & \mathbf{0}_{n\times n}\\
\mathbf{K} & \mathbf{0}_{n\times n} & \cdots & \mathbf{0}_{n\times n}\\
\vdots & \vdots & \ddots & \vdots\\
\mathbf{K} & \mathbf{0}_{n\times n} & \cdots & \mathbf{0}_{n\times n}
\end{array}\right]
\end{equation}

\end_inset

 where 
\begin_inset Formula $\mathbf{K}=\left(\frac{1}{n}\right)\mathbf{1}\mathbf{1}^{T}$
\end_inset

, and 
\begin_inset Formula $\mathbf{0}_{n\times n}$
\end_inset

 denotes the 
\begin_inset Formula $n\times n$
\end_inset

 all-zero matrix.
 
\end_layout

\begin_layout Standard
The high-order DAC algorithm with initial condition 
\begin_inset Formula $\mathbf{x}(-M+1)=,\ldots,=\mathbf{x}(-1)=\mathbf{x}(0)$
\end_inset

 is convergent if and only if 
\begin_inset Formula $\rho\left(\mathbf{H}-\mathbf{J}\right)<1$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2010"

\end_inset

.
 Then a spectral radius minimization problem to find the optimal 
\begin_inset Formula $\epsilon$
\end_inset

 and 
\begin_inset Formula $\gamma$
\end_inset

 for the high-order DAC algorithm is formulated as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{array}{cc}
\mbox{\mbox{Minimize }} & \rho\left(\mathbf{H}-\mathbf{J}\right)\\
\mbox{Subject to } & \epsilon,\gamma\in R
\end{array},\label{eq: High order spectral radius problem}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
As shown in Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: High order spectral radius problem"

\end_inset

, the convergence rate maximization for high order DAC algorithm can be
 cast into a spectral radius minimization problem.
 Finding the solution is not easy due to we have to solve the high-order
 polynomial to calculate eigenvalues.
 For example, the high-order polynomial of the eigenvalues of 
\begin_inset Formula $\mathbf{H-J}$
\end_inset

 when 
\begin_inset Formula $M=3$
\end_inset

, 
\begin_inset Formula $c_{1}=1$
\end_inset

 and 
\begin_inset Formula $c_{2}=1$
\end_inset

 is 
\begin_inset Formula 
\begin{equation}
f(\lambda)=\lambda^{3}-\left(1-\epsilon\lambda_{i}\left( L\right)\right)\lambda^{2}-\gamma\epsilon\lambda_{i}\left( L\right)\lambda+\gamma^{2}\epsilon\lambda_{i}\left( L\right)=0\label{eq: eigenvalue equation of H-J}
\end{equation}

\end_inset

where 
\begin_inset Formula $\lambda_{i}( L)$
\end_inset

 is the 
\begin_inset Formula $i^{th}$
\end_inset

 smallest eigenvalue of the Laplacian Matrix.
 
\end_layout

\begin_layout Standard
Since each 
\begin_inset Formula $\lambda_{i}( L),\; i=1,2,\cdots,n$
\end_inset

 with generate one equation which has 
\begin_inset Formula $M$
\end_inset

 roots, there are totally 
\begin_inset Formula $M\times n$
\end_inset

 eigenvalue for 
\begin_inset Formula $\mathbf{H-J}$
\end_inset

.
 Then, problem Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: High order spectral radius problem"

\end_inset

 can be written into 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
minimize the maximum absolute value of all the eigenvalues of 
\begin_inset Formula $\mathbf{H-J}$
\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 
\begin_inset Formula 
\begin{equation}
\begin{array}{cc}
\mbox{Minimize } & \mbox{max}\{\left|\lambda_{i}\left(\mathbf{H-J}\right)\right|\},\: i=1,2,\cdots,n\\
\mbox{Subject to } & \epsilon,\gamma\in R
\end{array},\label{eq:HO-DAC Opt. Problem}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Solve The Problem: Convergence rate maximization
\end_layout

\begin_layout Standard
The convergence rate optimization problem 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:HO-DAC Opt. Problem"

\end_inset

 of HO-DAC in undirected network can be graphically illustrated by the 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Find-minimum-rho(H)"

\end_inset

, where the surface of 
\begin_inset Formula $\mbox{max}\{\left|\lambda_{i}\left(\mathbf{H-J}\right)\right|\},\: i=1,2,\cdots,n$
\end_inset

 is plotted and the optimal solution 
\begin_inset Formula $\left(\epsilon{}_{opt},\gamma_{opt}\right)$
\end_inset

 is marked with a star.
 We denote the optimized spectral radius by 
\begin_inset Formula $\rho_{opt}=\mbox{\mbox{min}}\rho\left\{ \left(\mathbf{H}-\mathbf{J}\right)\right\} $
\end_inset

.
 
\end_layout

\begin_layout Standard
Since the eigenvalues in the high-order polynomial 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq: eigenvalue equation of H-J"

\end_inset

 are network topology dependent, the solution of the problem 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:HO-DAC Opt. Problem"

\end_inset

 may not have an unique analytical solution when the order is larger than
 second.
 In this case, the problem will be solved numerically, for example using
 steepest descent method.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/FirstYearReport/Lyx_v/images/3order_max_lambda.pdf
	width 10cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Find-minimum-rho(H)"

\end_inset

 Find the minimum on the surface, Illustration of Convergence rate optimization.
 
\begin_inset Formula $\min\left\{ \mbox{max}\left[\lambda_{i}\left(\mathbf{H-J}\right)\right]\right\} ,\: i=1,2,\cdots,n$
\end_inset

.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename Graph/Convergence region.eps
	width 10cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Convergence-Region"

\end_inset

Convergence Region for second order DAC.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $R_{1}$
\end_inset

 and 
\begin_inset Formula $R_{2}$
\end_inset

 are defined in 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Def Convergence region R1 R2"

\end_inset

.
 Note the dashed line separates the regions where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\lambda_{n'}\left(\mathbf{H}\right),\lambda_{n"}\left(\mathbf{H}\right)$
\end_inset

 are real and complex.
 In addition, optimal solution is always located on this line.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
However, the second order DAC, does exist analytical solution on some conditions.
 As 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2009a"

\end_inset

 pointed out, the convergence region 
\begin_inset Formula ${\cal R}$
\end_inset

 for second order DAC in undirected network which satisfy 
\begin_inset Formula $\rho\left(\mathbf{H}-\mathbf{J}\right)<1$
\end_inset

 is 
\begin_inset Formula 
\[
{\cal R}={\cal R}_{1}\cup{\cal R}_{2}
\]

\end_inset

where 
\begin_inset Formula 
\begin{eqnarray}
{\cal R}_{1} & = & \left\{ \frac{-1}{\epsilon\lambda_{n}\left( L\right)}<\gamma<1,0<\epsilon<\frac{1}{\lambda_{n}\left( L\right)}\right\} \\
{\cal R}_{2} & = & \left\{ \frac{-1}{\epsilon\lambda_{n}\left( L\right)}<\gamma<\frac{2}{\epsilon\lambda_{n}\left( L\right)}-1,\frac{1}{\lambda_{n}\left( L\right)}\leq\epsilon<\frac{3}{\lambda_{n}\left( L\right)}\right\} \label{eq:Def Convergence region R1 R2}
\end{eqnarray}

\end_inset

 Moreover, the of eigenvalues of 
\begin_inset Formula $\mathbf{H}$
\end_inset

 corresponding to eigenvalue of 
\begin_inset Formula $\lambda_{i}\left( L\right)$
\end_inset

 is denoted by 
\begin_inset Formula $\lambda_{i'}\left(\mathbf{H}\right)$
\end_inset

 and 
\begin_inset Formula $\lambda_{i"}\left(\mathbf{H}\right)$
\end_inset

, which is 
\begin_inset Formula 
\begin{eqnarray}
\lambda_{i'}\left(\mathbf{H}\right) & = & \frac{1}{2}\left[1-\epsilon\lambda_{i}\left( L\right)+\sqrt{\left(1-\epsilon\lambda_{i}\left( L\right)\right)^{2}+4\gamma\epsilon\lambda_{i}\left( L\right)}\right],\nonumber \\
\lambda_{i"}\left(\mathbf{H}\right) & = & \frac{1}{2}\left[1-\epsilon\lambda_{i}\left( L\right)-\sqrt{\left(1-\epsilon\lambda_{i}\left( L\right)\right)^{2}+4\gamma\epsilon\lambda_{i}\left( L\right)}\right].\label{eq:2nd-DAC lambda_H solution}
\end{eqnarray}

\end_inset

 
\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\lambda_{2}\left( L\right)\leq\dots\leq\lambda_{n}\left( L\right)$
\end_inset

, in the convergence region of the second order DAC algorithm, the optimization
 problem 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:HO-DAC Opt. Problem"

\end_inset

 can be equivalent to 
\begin_inset Formula 
\[
\begin{array}{cc}
\mbox{Minimize } & \mbox{max}\{\left|\lambda_{2'}\left(\mathbf{H}\right)\right|,\left|\lambda_{2"}\left(\mathbf{H}\right)\right|,\left|\lambda_{n'}\left(\mathbf{H}\right)\right|,\left|\lambda_{n"}\left(\mathbf{H}\right)\right|\}\\
\mbox{Subject to } & \epsilon,\gamma\in R
\end{array},
\]

\end_inset


\end_layout

\begin_layout Standard
Finding the optimal solutions needs consideration of different combinations
 of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\lambda_{2'}\left(\mathbf{H}\right),\lambda_{2"}\left(\mathbf{H}\right),\lambda_{n'}\left(\mathbf{H}\right),\lambda_{n"}\left(\mathbf{H}\right)$
\end_inset

 when they are real value or complex value.
 However, for a connected network, the 
\begin_inset Formula $\lambda_{2'}\left(\mathbf{H}\right),\lambda_{2"}\left(\mathbf{H}\right)$
\end_inset

 are real and 
\begin_inset Formula $\lambda_{n'}\left(\mathbf{H}\right),\lambda_{n"}\left(\mathbf{H}\right)$
\end_inset

 are complex values in the convergence region.
 When the minimum is achieved, the following equation satisfied
\begin_inset Formula 
\[
\left|\lambda_{2'}\left(\mathbf{H}\right)\right|=\left|\lambda_{n'}\left(\mathbf{H}\right)\right|=\left|\lambda_{n"}\left(\mathbf{H}\right)\right|
\]

\end_inset

Thus, by solving this equation, we have the optimal solution for second
 order DAC algorithm.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
\epsilon{}_{opt,SO} & = & \frac{3\lambda_{n}( L)+\lambda_{2}( L)}{\lambda_{n}( L)\left[\lambda_{n}( L)+3\lambda_{2}( L)\right]}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\gamma_{opt,SO}=-\frac{\left[\lambda_{n}( L)-\lambda_{2}( L)\right]^{2}}{\left[\lambda_{n}( L)+3\lambda_{2}( L)\right]\left[3\lambda_{n}( L)+\lambda_{2}( L)\right]}
\end{equation}

\end_inset

These parameters could be floored to all sensors before the algorithm start
 so that it converges faster.
\end_layout

\begin_layout Standard
Besides these results, we need to point out that the optimal solution 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\epsilon{}_{opt,SO}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
and 
\begin_inset Formula $\gamma_{opt,SO}$
\end_inset

 have the f
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
ollowing relationship
\begin_inset Formula 
\[
\gamma_{opt,SO}=\frac{\left[1-\epsilon{}_{opt,SO}\lambda_{n}\left( L\right)\right]^{2}}{-4\epsilon{}_{opt,SO}\lambda_{n}\left( L\right)}
\]

\end_inset

which implies the value under the square root in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:2nd-DAC lambda_H solution"

\end_inset

 is equal to zero, and 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\lambda_{n'}\left(\mathbf{H}\right),\lambda_{n"}\left(\mathbf{H}\right)$
\end_inset

 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
are all real values.
 Additionally, the optimal solution is located just on the board line of
 the regions, where 
\begin_inset Formula $\lambda_{n'}\left(\mathbf{H}\right),\lambda_{n"}\left(\mathbf{H}\right)$
\end_inset

 is real and complex respectably.
 
\end_layout

\begin_layout Subsection
Simulation and Algorithms Performance 
\end_layout

\begin_layout Standard
To test the performance of high-order DAC algorithm with different orders,
 a simulation is carry out on 1000 random generated networks.
 The methods and parameters of network generation are illustrated in fig.
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Net-N16-R0,3"

\end_inset

.
 The algorithm's performance is evaluated by the average spectral radius
 and average mean square error, shown in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:DAC-comparation"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Random Network Generation
\end_layout

\begin_layout Standard
The following is a simulation of network generation to show how the wireless
 sensor networks is distributed.
 First, we randomly and uniformly distribute a certain number of nodes in
 an unit square.
 Second, each sensor randomly choose a local initial value has equally probabili
ty density function.
 Finally, connect any two nodes if their satisfy a certain communication
 constrains.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../FirstYearReport/Lyx_v/images/Net50Edges200.eps
	lyxscale 50
	width 7cm
	height 7cm
	BoundingBox 250bp 0bp 750bp 513bp
	clip

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Net-N50-E200"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../FirstYearReport/Lyx_v/images/Network_N16_R0,3.pdf
	lyxscale 120
	width 7cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Net-N16-R0,3"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Random-Network"

\end_inset

Randomly generated networks (a) 50 nodes and 200 edges (b) 16 nodes and
 radius constrain 
\begin_inset Formula $R=0.3$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
There are some cases to generate the links between nodes.
\end_layout

\begin_layout Case
Consider the graph show in the Fig.
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Net-N50-E200"

\end_inset

, which has 50 nodes and 200 edges.The number of nodes and edges are fixed;
 50 nodes are randomly and uniformly distribute in the unit square; a list
 that contains 200 shortest edges is created; Nodes are connected if the
 edges belongs to the list.
 
\end_layout

\begin_layout Case
The network in Fig.
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Net-N16-R0,3"

\end_inset

 is generating by connecting any two nodes if their distance is less than
 the communication radius constrain 
\begin_inset Formula $R$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Performance Comparison for Asymptotic DAC
\end_layout

\begin_layout Standard
The figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DAC-SR-comp"

\end_inset

 shows the optimal spectral radius for DAC algorithms with different communicati
on radius constraints.
 The performance for DAC algorithms with different orders are compared by
 optimal spectral radius 
\begin_inset Formula $\rho_{opt}=\mbox{\mbox{min}}\rho\left\{ \left(\mathbf{H}-\mathbf{J}\right)\right\} $
\end_inset

, which has the relationship with convergence rate given by 
\begin_inset Formula $r_{opt}=-log\left(\rho_{opt}\right)$
\end_inset

.
 Y-axis is corresponding to the minimum spectral radius and x-axis is correspond
ing to the radius constrain.
 For each instance of DAC algorithm, the result is the minimum on the surface
 
\begin_inset Formula $\mbox{max}\{\left|\lambda_{i}\left(\mathbf{H-J}\right)\right|\}$
\end_inset

 obtained by numerical searching.
 Each curve is the average of simulations realized for 1000 instance of
 DAC initialized with random local value vectors and random networks.
\end_layout

\begin_layout Standard
In another point of view, figure.
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DAC MSE Compare"

\end_inset

 plots the convergence behavior of mean square error of high-order DAC algorithm
s together with first order DAC on random network.
 The MSE is defined by 
\begin_inset Formula 
\begin{equation}
MSE(k)=\frac{1}{n}\sum_{i=1}^{n}\left|x_{i}(k)-\bar{x}\right|^{2}.
\end{equation}

\end_inset

which Actually it is the Euclidean distance between current local vector
 and the global average.
 shows the result when radius constrain 
\begin_inset Formula $R$
\end_inset

 is 
\begin_inset Formula $0.3$
\end_inset

.
 In observing the gradient of curves, it is apparent that higher-order DAC
 algorithm have larger convergence rate.
 However, there are negligible improvement for the fourth order DAC compared
 to the third order one.
 Furthermore, high-order DAC has a MSE overshoot at the beginning.
 This phenomenon happens especially when communication radius is small.
 Second order DAC algorithm does have a faster convergence rate than first
 order algorithm as the slop of the curve is steeper.
 But it become worse as it converge to error tolerance 
\begin_inset Formula $10^{-6}$
\end_inset

 more later than the first order algorithm.
 Therefore, A hybrid algorithm is proposed to overcome this disadvantage.
 Its step size and forgetting factor are equal to the of first order DAC
 step size and second order DAC forgetting factor respectively.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename ../FirstYearReport/Lyx_v/images/Spectrum radius Compare_old_Ord1234.eps
	lyxscale 60
	width 7cm
	height 6cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:DAC-SR-comp"

\end_inset

 DAC algorithms performance comparison compared by spectral radius 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename ../FirstYearReport/Lyx_v/images/DAC_Compr_ord1234&hybrid.eps
	lyxscale 60
	width 7cm
	height 6cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:DAC MSE Compare"

\end_inset

 DAC algorithms performance compared by meam square error 
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:DAC-comparation"

\end_inset

DAC algorithms comparison 
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
\begin_inset CommandInset label
LatexCommand label
name "sec:Finite-Time-Distributed-Consensu"

\end_inset

Finite-Time Distributed Consensus Algorithm
\end_layout

\begin_layout Standard
Finite-Time Distributed Consensus Algorithm (FT-DCA) tries to find the consensus
 value after each node run the FO-DCA algorithm iteratively for a certain
 number of time.
 This is based on the assumption that after a certain number of iterations,
 local values would contain sufficient information to estimate the consensus
 value.
 
\end_layout

\begin_layout Definition
Given the network 
\begin_inset Formula $\mathcal{G}$
\end_inset

, and initial local value vector 
\begin_inset Formula $\mathbf{x}\left(0\right)$
\end_inset

, it is said the algorithm achieves a finite-time consensus if it solve
 a consensus problem, and there exist a time 
\begin_inset Formula $t^{*}$
\end_inset

 and the consensus value 
\begin_inset Formula $\bar{x}$
\end_inset

 such that 
\begin_inset Formula $x_{i}\left(t\right)=\bar{x}$
\end_inset

, for all time 
\begin_inset Formula $t>t^{*}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Motivated by the works in 
\begin_inset CommandInset citation
LatexCommand cite
key "Kokiopoulou2007"

\end_inset

, we try to decompose the local value vector in a form which reveals an
 important property of its iteration.
 Therefore we propose a filtering technique to estimate the consensus value.
 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
In the network that adopts first order linear consensus algorithm, each
 node has a number of consecutive local values
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 obtained by Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:1st iter. ni"

\end_inset

.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
There exists a linear filter.
 If each node passes its 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
consecutive
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 local values through this
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 filter, the output after a certain time is the global average of the initial
 values over the network.
 Compared to first order DCA algorithm, no more information exchanged between
 nodes is needed.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
Such a filter is defined as the consensus finding filter.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "Def.A-consensus-finding"

\end_inset

A consensus finding filter is a linear filter defined by 
\begin_inset Formula $\mathbf{h}\in R^{d}$
\end_inset

, such that by passing 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
through 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
local values 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $x_{i}(k)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
obtained by Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:1st iter. ni"

\end_inset

, 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
the output 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\hat{x}_{i}(k)=\mathbf{h}(k)*x_{i}(k)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 is the consensus value 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\overline{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}(0)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 of the network after 
\begin_inset Formula $k$
\end_inset

 step 
\begin_inset Formula $\left(k\geqslant m\right)$
\end_inset

, where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $m$
\end_inset

 is the number of
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 distinct and nonzero eigenvalues of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
the weight matrix 
\begin_inset Formula $ W$
\end_inset

.
 And 
\begin_inset Formula $ W$
\end_inset

 satisfies the convergence condition 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:convege condition W"

\end_inset

.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Local-Value-Decomposition"

\end_inset

Local Value Decomposition 
\end_layout

\begin_layout Standard
Suppose an undirected network with 
\begin_inset Formula $n$
\end_inset

 nodes, where duplex communication is possible in each link.
 Therefore, the associated weight matrix 
\begin_inset Formula $ W\in\mathbf{R}^{n\times n}$
\end_inset

 is symmetric and diagonalizable.
 And there are 
\begin_inset Formula $n$
\end_inset

 linear independent eigenvectors of the weight matrix.

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 Thus, any initial value vector can be written in a linear combination of
 these eigenvectors, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{x}\left(0\right)=\alpha_{1}\mathbf{e}_{1}+\alpha_{2}\mathbf{e}_{2}+\ldots+\alpha_{n}\mathbf{e}_{n}
\end{equation}

\end_inset

where 
\begin_inset Formula $\alpha_{i}(i=1,2,\ldots,n)$
\end_inset

 is the coefficient.
 For 
\begin_inset Formula $k=1,2,3,...$
\end_inset

 we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
\mathbf{x}\left(k\right) & = &  W^{k}\left[\alpha_{1}\mathbf{e}_{1}+\alpha_{2}\mathbf{e}_{2}+\ldots+\alpha_{n}\mathbf{e}_{n}\right]\nonumber \\
 & = & \alpha_{1}\lambda_{1}^{k}\mathbf{e}_{1}+\alpha_{2}\lambda_{2}^{k}\mathbf{e}_{2}+\ldots+\alpha_{n}\lambda_{n}^{k}\mathbf{e}_{n}\label{eq:x(k) decomposition}\\
 & = & \sum_{i=1}^{n}\alpha_{i}\lambda_{i}^{k}\mathbf{e}_{i}\nonumber 
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $\lambda_{i}$
\end_inset

 is the eigenvalue of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $ W$
\end_inset

.
 
\end_layout

\begin_layout Standard
By rewriting 
\begin_inset Formula $\mathbf{x}\left(k\right)$
\end_inset

, it is clear that if all eigenvalues of the weight matrix are known, the
 node values vector
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 is predictable and the consensus value can be found
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
.
 For any node 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $i=1,2,\ldots n$
\end_inset

, its local value at time 
\begin_inset Formula $k$
\end_inset

 can be written as
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 
\begin_inset Formula 
\begin{equation}
x_{i}\left(k\right)=\alpha_{1}\lambda_{1}^{k}e_{i1}+\alpha_{2}\lambda_{2}^{k}e_{i2}+\ldots+\alpha_{n}\lambda_{n}^{k}e_{in}
\end{equation}

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
where 
\begin_inset Formula $e_{ij}$
\end_inset

 is the 
\begin_inset Formula $i^{th}$
\end_inset

 component of eigenvector 
\begin_inset Formula $\mathbf{e}_{j}$
\end_inset

.
 Because of algebraic multiplicity of some eigenvalues, the equation can
 be modified by combining the terms with the same eigenvalues.
 Zero eigenvalues are ignored as they have no contribution in this equation.
 Suppose 
\begin_inset Formula $ W$
\end_inset

 has 
\begin_inset Formula $m$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 distinct and nonzero eigenvalues, denoted by 
\begin_inset Formula $\lambda_{1},\lambda_{2},\ldots,\lambda_{m}$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
, then 
\begin_inset Formula $x_{i}\left(k\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 evolves into
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula 
\begin{equation}
x_{i}\left(k\right)=\beta_{i1}\lambda_{1}^{k}+\beta_{i2}\lambda_{2}^{k}+\ldots+\beta_{im}\lambda_{m}^{k}
\end{equation}

\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
where
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $\beta_{ij}$
\end_inset

 is the coefficient after combination.
 
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Find-the-Consensus"

\end_inset

Find the Consensus Value by Linear Filter
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
Let the sample vector 
\begin_inset Formula $\mathbf{y}_{i}(k,d)\in R^{d}$
\end_inset

 is defined by the history of 
\begin_inset Formula $x_{i}(k),$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{y}_{i}(k,d)=\left[x_{i}(k),x_{i}(k-1),\ldots x_{i}(k-d+1)\right]^{\mathrm{T}}\label{eq:def. y(k,m)}
\end{equation}

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
and the Vandermonde matrix whose entries are the power of eigenvalues
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{V}(k,d)=\left[\begin{array}{cccc}
\lambda_{1}^{k} & \lambda_{2}^{k} & \cdots & \lambda_{m}^{k}\\
\lambda_{1}^{k-1} & \lambda_{2}^{k-1} & \cdots & \lambda_{m}^{k-1}\\
\vdots & \vdots & \ddots & \vdots\\
\lambda_{1}^{k-d+1} & \lambda_{2}^{k-d+1} & \cdots & \lambda_{m}^{k-d+1}
\end{array}\right]\label{eq:def. Lamda(k,m)}
\end{equation}

\end_inset

and 
\begin_inset Formula $\mathbf{b}_{i}\left(d\right)=\left[\beta_{i1},\beta_{i2},\cdots\beta_{id}\right]^{\mathrm{T}}$
\end_inset

, then we have the following equation satisfied
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{y}_{i}(k,d)=\mathbf{V}(k,d)\mathbf{b}_{i}\left(d\right)\label{eq:Vander matrix and consensus-d*m}
\end{equation}

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
To obtain the consensus value 
\begin_inset Formula $\bar{x}$
\end_inset

 for node 
\begin_inset Formula $i$
\end_inset

,
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 we need to take sufficient samples of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $x_{i}(k)$
\end_inset


\family default
\series bold
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
and solve Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Vander matrix and consensus-d*m"

\end_inset

, where 
\begin_inset Formula $d$
\end_inset

 should at least equal or larger than
\family default
\series bold
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 
\begin_inset Formula $m$
\end_inset


\series default
, which is the number of distinct and nonzero eigenvalues of weight matrix
 
\begin_inset Formula $ W$
\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
Let 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit

\begin_inset Formula $A(k,m)=\mathbf{V}^{-1}(k,m)$
\end_inset

 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
and
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 the first row of 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $A(k,m)$
\end_inset

 is given by
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula 
\begin{equation}
\mathbf{h}=\left[A_{11}(k,m),A_{12}(k,m),\ldots,A_{1m}(k,m)\right]^{\mathrm{T}}
\end{equation}

\end_inset

 we have 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula 
\begin{equation}
\beta_{i1}=\mathbf{h}^{\mathrm{T}}\mathbf{y}_{i}(k,m)\label{eq:Find Consensus m order}
\end{equation}

\end_inset

 Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Find Consensus m order"

\end_inset

 shows that the consensus value can be calculated 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
by the filter defined in Def.
\begin_inset CommandInset ref
LatexCommand ref
reference "Def.A-consensus-finding"

\end_inset

.
 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
It is worth noting that Vandermonde matrix is related to a polynomial interpolat
ion problem and can be easily inverted in terms of Lagrange basis polynomials
 
\begin_inset CommandInset citation
LatexCommand cite
key "Prass2007"

\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 Due to this reason, this method can be treated as an extrapolation method
 which find the consensus value at infinity.
 At the same time, we only need to find out the first coefficient 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\beta_{i1}$
\end_inset

 in the distributed averaging.
 Therefore, 
\strikeout default
\uuline default
\uwave default
only the elements in the corresponding row of 
\strikeout off
\uuline off
\uwave off

\begin_inset Formula $\mathbf{V}^{-1}(k,m)$
\end_inset


\strikeout default
\uuline default
\uwave default
 need to be found.
 This approach can save lots of computation time in the inverting of Vandermonde
 matrix.
 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
Since 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
simulation result shows that 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\mathbf{h}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 is only depends the associated Vandermonde matrix
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\begin_inset Formula $\mathbf{V}(k,m)$
\end_inset

 which is 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
is independent of the node’s initial values and time index 
\begin_inset Formula $k$
\end_inset

.
 Therefore, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
each node in the network could find the consensus value at any time 
\begin_inset Formula $k\geqslant m$
\end_inset

 by passing a number of consecutive local values through this filter.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 In addition, all nodes in this network may share the same filter, which
 means all the filters have the same impulse response.
 However, such a consensus finding filter it is not unique.
 As an example, a number of filters which have different impulse response
 or filter lengths are found by different samples 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
of 
\begin_inset Formula $x_{i}(k)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
.
  Each node could choose its own, but filter length determines the how many
 time-steps before a node could find 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
the consensus value.
 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
Suppose we take 
\begin_inset Formula $d$
\end_inset

 samples of 
\begin_inset Formula $x_{i}(k)$
\end_inset

, where 
\begin_inset Formula $d>m$
\end_inset

.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
Because
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 the Vandermonde matrix 
\begin_inset Formula $\mathbf{V}(k,d)\in R^{d\times m}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 is non-square, we introduce the Moore-Penrose pseudo inverse to find the
 least mean square solution.
 
\end_layout

\begin_layout Standard
Let
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
A(k,d)=\mathbf{V}^{+}(k,d)
\end{equation}

\end_inset

where 
\begin_inset Formula $^{+}$
\end_inset

 denote the Moore-Penrose pseudo inverse 
\begin_inset CommandInset citation
LatexCommand cite
key "Piziak2007"

\end_inset

.
 And
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 the first row of 
\begin_inset Formula $A(k,d)$
\end_inset

 is given by 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{h}'=\left[A{}_{11}(k,d),A_{12}(k,d),\ldots,A_{1d}(k,d)\right]^{\mathrm{T}}
\end{equation}

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
Still, the value 
\strikeout off
\uuline off
\uwave off

\begin_inset Formula $\beta_{i1}=\mathbf{h}'^{\mathrm{T}}\mathbf{y}_{i}(k,m)$
\end_inset

 
\strikeout default
\uuline default
\uwave default
is an accurate estimation of consensus value.
 Therefore, another consensus finding filter is obtained.
\end_layout

\begin_layout Standard
Due to the multiplication of the consensus finding filter, the set of filter
 is defined by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
H=\{\mathbf{h}\in R^{d}|\forall d\geqslant m,\:\mathbf{h}^{\mathrm{T}}\mathbf{y}_{i}(k,d)=\bar{x}\}
\end{equation}

\end_inset

However, the shortest filter has its length equal to 
\begin_inset Formula $m$
\end_inset

, which means node can only have the consensus value after 
\begin_inset Formula $m$
\end_inset

 steps.
 
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:Numerical-Simulation"

\end_inset

, the performance of this algorithm is shown by comparing it with the first
 order DAC algorithm using optimal weight matrix in 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Inverse the Vandermonde matrix
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
The Vandermonde matrix has its application in some problems like polynomial
 fitting, reconstruction of distributions from their moments, and so on.
 Solving Vandermonde matrix is related to a polynomial interpolation problem
 and can be easily inverted in terms of Lagrange basis polynomials.
 It can be very difficult to invert in other way if the size of the matrix
 is large, as the Vandermonde matrix is T is notoriously ill-conditioned
 by its nature.
 It is a good way to always work on the problems related to Vandermonde
 matrix in double precision or higher.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $V_{m}$
\end_inset

 be the Vandermonde matrix of order 
\begin_inset Formula $m$
\end_inset

 given by 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
V_{m}=\left[\begin{array}{cccc}
\lambda_{1} & \lambda_{2} & \cdots & \lambda_{m}\\
\lambda_{1}^{2} & \lambda_{2}^{2} & \cdots & \lambda_{m}^{2}\\
\vdots & \vdots & \ddots & \vdots\\
\lambda_{1}^{m} & \lambda_{2}^{m} & \cdots & \lambda_{m}^{m}
\end{array}\right]\label{eq:Vander Matrix}
\end{equation}

\end_inset

Then the equation 
\begin_inset Formula 
\begin{equation}
\left[\begin{array}{cccc}
\lambda_{1} & \lambda_{2} & \cdots & \lambda_{m}\\
\lambda_{1}^{2} & \lambda_{2}^{2} & \cdots & \lambda_{m}^{2}\\
\vdots & \vdots & \ddots & \vdots\\
\lambda_{1}^{m} & \lambda_{2}^{m} & \cdots & \lambda_{m}^{m}
\end{array}\right]\left[\begin{array}{c}
\beta_{1}\\
\beta_{2}\\
\vdots\\
\beta_{m}
\end{array}\right]=\left[\begin{array}{c}
y_{1}\\
y_{2}\\
\vdots\\
y_{m}
\end{array}\right]\label{eq:Vander Eq.}
\end{equation}

\end_inset

is related to the problem of moments: Given the values of all 
\begin_inset Formula $\lambda_{i}$
\end_inset

, find the unknown coefficients 
\begin_inset Formula $b_{i}$
\end_inset

, so that they match the given values 
\begin_inset Formula $y_{i}$
\end_inset

 of the first 
\begin_inset Formula $m$
\end_inset

 moments.
 
\end_layout

\begin_layout Standard
Its inverse is closely related to Lagrange's polynomial interpolation formula.
 
\end_layout

\begin_layout Standard
Let the polynomial of degree 
\begin_inset Formula $m$
\end_inset

 defined by 
\begin_inset Formula 
\begin{equation}
P_{j}\left(\lambda\right)=\prod_{\begin{array}{c}
i=1\\
i\neq j
\end{array}}^{m}\frac{\lambda-\lambda_{i}}{\lambda_{j}-\lambda_{i}}=\sum_{k=1}^{m}b_{jk}\lambda^{k-1}\label{eq:Lagrange's polynomial}
\end{equation}

\end_inset

The polynomial 
\begin_inset Formula $P_{j}\left(\lambda\right)$
\end_inset

 a function of 
\begin_inset Formula $\lambda$
\end_inset

 and is specially designed so that it is equal to zero at all 
\begin_inset Formula $\lambda_{i}$
\end_inset

 except 
\begin_inset Formula $i=j$
\end_inset

 and takes on a value of one at 
\begin_inset Formula $\lambda=\lambda_{j}$
\end_inset

.
 In other words, 
\begin_inset Formula 
\[
P_{j}\left(\lambda_{i}\right)=\delta_{ij}=\sum_{k=1}^{m}b_{jk}\lambda_{i}^{k-1}
\]

\end_inset

where 
\begin_inset Formula $\delta_{ij}=1$
\end_inset

 when 
\begin_inset Formula $i=j$
\end_inset

 .
 The equation says that 
\begin_inset Formula $b_{jk}$
\end_inset

 is exactly the inverse of the matrix 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Vander Matrix"

\end_inset

, with the subscript 
\begin_inset Formula $k$
\end_inset

 as the column index.
 
\end_layout

\begin_layout Standard
To drive the analytical expression of 
\begin_inset Formula $b_{jk}$
\end_inset

 and make it as easy as possible, let's define some intermediate result.
 Define the polynomial 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $q_{j}\left(\lambda\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 and work out its coefficients
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
q_{j}\left(\lambda\right) & = & \frac{\prod_{i=1}^{m}\left(\lambda-\lambda_{i}\right)}{\left(\lambda-\lambda_{j}\right)}=\prod_{i=1,i\neq j}^{m}\left(\lambda-\lambda_{i}\right)\label{eq:intermindia polynomial}\\
 & = & c_{j,m}\lambda^{m-1}+c_{j,m-1}\lambda^{m-2}+\ldots+c_{j,2}\lambda+c_{j,1}\nonumber 
\end{eqnarray}

\end_inset

Examining the polynomial 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Lagrange's polynomial"

\end_inset

 and polynomial 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:intermindia polynomial"

\end_inset

, we have 
\begin_inset Formula 
\begin{eqnarray*}
b_{jk} & = & \frac{c_{j,m}}{q_{j}\left(\lambda_{j}\right)}
\end{eqnarray*}

\end_inset

Therefore, the solution of Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Vander Eq."

\end_inset

 is just the inverse of Vandermonde matrix time the vector on the right.
 
\begin_inset Formula 
\[
\beta_{j}=\sum_{k=1}^{m}b_{jk}y_{k}
\]

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
If we only need to calculate the consensus value, as explained in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:Find-the-Consensus"

\end_inset

 only the 
\strikeout default
\uuline default
\uwave default
elements in the corresponding row of 
\strikeout off
\uuline off
\uwave off
inverse Vandermonde's matrix
\strikeout default
\uuline default
\uwave default
 need to be found.
 The computation saving can be enormous by this approach.
\end_layout

\begin_layout Subsubsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Numerical-Simulation"

\end_inset

Numerical Simulation
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename ../Distributed Consensus Algorithm/Report_DAC/Net_Weight/graph with 8 nodes and 17 edges.pdf

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Graph in Xiao'paper"

\end_inset

Graph with optimal weights which maximize convergence rate 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Consider the graph from 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset

, the weight matrix 
\series bold

\begin_inset Formula $ W$
\end_inset


\series default
 corresponding to this graph is symmetric and has eigenvalues 
\begin_inset Formula $\lambda( W)=\{1,0.6,0.4,0,0,0,-0.4,-0.6\}$
\end_inset

.
 The time index 
\begin_inset Formula $k$
\end_inset

 can be chosen large enough so that there are only positive powers in the
 matrix 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset Formula $\mathbf{V}(k,d)$
\end_inset

.
 For example, there are
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 5 distinct and nonzero eigenvalues of 
\series bold

\begin_inset Formula $ W$
\end_inset


\series default
, so we choose 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
the time index 
\begin_inset Formula $k=5$
\end_inset

 and 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit

\begin_inset Formula $d=5$
\end_inset

 which is the minimum filter length
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula 
\[
\mathbf{V}(5,5)=\left[\begin{array}{ccccc}
1 & 0.0778 & 0.0102 & -0.0102 & -0.0778\\
1 & 0.1296 & 0.0256 & 0.0256 & 0.1296\\
1 & 0.216 & 0.064 & -0.064 & -0.216\\
1 & 0.36 & 0.16 & 0.16 & 0.36\\
1 & 0.6 & 0.4 & -0.4 & -0.6
\end{array}\right]
\]

\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
 the first row of the inverse matrix 
\begin_inset Formula $\mathbf{V}^{-1}(5,5)$
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
gives the consensus finding filter 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbf{h}=\left[1.8601,\;0,\;-0.9673,\;0,\;0.1071\right]^{\mathrm{T}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename ../Distributed Consensus Algorithm/Report_DAC/MSE/MSE_Filter vs FODAC.eps
	width 8cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "cap:perform. Consensus Filter"

\end_inset

Performance of the first order iteration with optimal matrix vs.
 consensus finding filter algorithm
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For any random generated 
\begin_inset Formula $\mathbf{x}(0)\in R^{n}$
\end_inset

, node values vector 
\begin_inset Formula $\mathbf{x}(k)$
\end_inset

 is updated by the iteration Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:first order matrix"

\end_inset

.
 At the same time each node passes its local values though filter 
\begin_inset Formula $\mathbf{h}$
\end_inset

.
 Filter output is given by 
\begin_inset Formula $\hat{x}_{i}(k)=\mathbf{h}(k)*x_{i}(k)$
\end_inset

.
 Fig.
\begin_inset CommandInset ref
LatexCommand ref
reference "cap:perform. Consensus Filter"

\end_inset

 compares the first order DAC (FO-DAC) algorithm with optimal matrix and
 the proposed algorithm with consensus finding filter.
 The performance is evaluated by the mean square error (MSE), defined by
 
\begin_inset Formula $\mbox{MSE}_{\mbox{FO-DAC}}(k)=\sum_{i\in\mathcal{N}}E[\left|x_{i}(k)-\bar{x}\right|^{2}]$
\end_inset

, 
\begin_inset Formula $\mbox{MSE}_{\mbox{filter}}(k)=\sum_{i\in\mathcal{N}}E[\left|\alpha_{i}(k)-\bar{x}\right|^{2}]$
\end_inset

 respectively, where 
\begin_inset Formula $\bar{x}=(1/n)\sum_{i\in\mathcal{N}}x_{i}(0)$
\end_inset

.
 The result shows that the consensus finding filter calculate the consensus
 value after a finite number of iteration and MSE drops dramatically to
 the quantization error at the same time.
 
\end_layout

\begin_layout Subsection
Generalized FT-DAC: Unknown Network Topology 
\end_layout

\begin_layout Standard
In the section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Find-the-Consensus"

\end_inset

, It shows if each node has knowledge of the network topology (for example,
 eigenvalues of the weight matrix), the consensus value can be calculated
 by a linear combination of past local values.
 However, having knowledge of the network topology in every node is a strong
 assumption.
 Although a distributive algorithm to calculate the linear combination has
 also been introduced in 
\begin_inset CommandInset citation
LatexCommand cite
key "Sundaram2007"

\end_inset

.
 This method requires several runs of the consensus algorithm initialized
 with a set of linear independent vectors.
 Alternatively, the original consensus algorithm can run many instances
 in parallel with a set of independent initial values.
 However, the data transmission at each iteration increases.
 In addition, this method may not reliable to topology changes during the
 of multiple re-initializations of original consensus algorithm.
 
\end_layout

\begin_layout Standard
Here we propose a generalized finite-time consensus algorithm without knowledge
 of network topology.
 It also does not require re-initialization of the original consensus algorithm
 for several times.
 Before introducing the algorithm, there are too important linear filter
 need to be introduced, as the algorithm is based on the properties of these
 filters.
\end_layout

\begin_layout Subsubsection
Linear Predictor For Local Value 
\end_layout

\begin_layout Standard
In observing the convergence behavior of each node's local value sequence,
 one would come to the idea that the sequence must obeys some rule as it
 converges.
 In section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Local-Value-Decomposition"

\end_inset

, it is shown that local value vector can be decomposed in terms of eigenvalues
 and eigenvectors.
 Based on this fact, a consensus estimation method by inverting the Vandermonde
 matrix and a information flooding techniques are proposed.
\end_layout

\begin_layout Standard
However, another important property of the FO-DCA need to be highlighted
 in this section, because it will also inspire some ideas on signal processing
 and applications in distributed systems.
\end_layout

\begin_layout Standard
To see how this property can be explained in an equation, we use the concept
 of minimal polynomial of the weight matrix 
\begin_inset Formula $ W$
\end_inset

.
 For any weight matrix 
\begin_inset Formula $ W$
\end_inset

, it has distinct eigenvalues denoted by 
\begin_inset Formula $\lambda_{1},\lambda_{2},\ldots,\lambda_{m},$
\end_inset

 then the minimal polynomial can be obtained by 
\begin_inset Formula 
\[
p(\lambda)=\prod_{i=1}^{m}\left(\lambda-\lambda_{i}\right)^{r_{i}}
\]

\end_inset

where 
\begin_inset Formula $r_{i}$
\end_inset

 is the size of the largest Jordan block of 
\begin_inset Formula $ W$
\end_inset

 corresponding to eigenvalue 
\begin_inset Formula $\lambda_{i}$
\end_inset

.
 The minimal polynomial can also be expanded into the form 
\begin_inset Formula 
\[
p\left(\lambda\right)=\lambda^{r+1}+a_{r}\lambda^{r}+\ldots+a_{1}\lambda+a_{0}
\]

\end_inset

where 
\begin_inset Formula $r+1$
\end_inset

 is the degree of the minimal polynomial.
 Since the minimal polynomial of matrix 
\begin_inset Formula $ W$
\end_inset

 satisfies 
\begin_inset Formula $p\left( W\right)=0$
\end_inset

.
 We have
\begin_inset Formula 
\[
 W^{r+1}+a_{r} W^{r}+\ldots+a_{1} W+a_{0} I=0
\]

\end_inset

if we multiply each side with initial value vector, and use the fact 
\begin_inset Formula $\mathbf{x}\left(k+1\right)= W^{k+1}\mathbf{x}\left(0\right)$
\end_inset

, the above equation evolves into
\begin_inset Formula 
\begin{equation}
\mathbf{x}\left(r+1\right)+a_{r}\mathbf{x}\left(r\right)+\ldots+a_{1}\mathbf{x}\left(1\right)+a_{0}\mathbf{x}\left(0\right)=0\label{eq:local value linear combination}
\end{equation}

\end_inset

Therefore, for any 
\begin_inset Formula $k\geq r$
\end_inset


\begin_inset Formula 
\begin{equation}
\mathbf{x}\left(k+1\right)=-a_{r}\mathbf{x}\left(k\right)-\ldots-a_{1}\mathbf{x}\left(k-r+1\right)+a_{0}\mathbf{x}\left(k-r\right)\label{eq:local value linear predictor}
\end{equation}

\end_inset

This equation shows that the vector sequence can be predict by a FIR filter
 with coefficient given by 
\begin_inset Formula $\left[-a_{r},-a_{r-1},\ldots,-a_{0}\right].$
\end_inset


\end_layout

\begin_layout Standard
Given the local value vector sequence obtained by FO-DCA, one may instantly
 comes to the idea of applying an adaptive filter algorithm to estimate
 the set of coefficient.
 For example, LMS, LSL and Kalman filter algorithms.
 One advantage of the adaptive filter algorithm is that when the network
 topology is changed, the filter could adaptively change its coefficient
 during the iteration.
 
\end_layout

\begin_layout Standard
In the next section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Cons.Find.Filter and relationship"

\end_inset

, we will show that the relationship of linear predictor of local value
 and the consensus finding filter.
\end_layout

\begin_layout Subsubsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Cons.Find.Filter and relationship"

\end_inset

The Consensus Finding Filter and The Relationship with Linear Predictor
 
\end_layout

\begin_layout Standard
If matrix 
\begin_inset Formula $ W$
\end_inset

 satisfies the condition in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "thm:convergence condition"

\end_inset

 there is a simple eigenvalue equals to one.
 As shown in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Cons.Find.Filter and relationship"

\end_inset

, the consensus finding filter is given by the row of inverse of Vandermonde's
 matrix which corresponding to an eigenvalue equals to one.
 Without loss of generality, let the first eigenvalue 
\begin_inset Formula $\lambda_{1}=1$
\end_inset

.
 Thus, the corresponding row of the inverse of Vandermonde's Matrix is equal
 to the consensus finding filter, whose coefficients are given by the coefficien
ts 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $b_{1k}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 in the polynomial.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{h}=\left[b_{11},b_{12},\ldots,b_{1m}\right]\label{eq:Consensus Finding filter Entry}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Examining the minimal polynomial of weight matrix.
 (Since the symmetric weight matrix has only 
\begin_inset Formula $m$
\end_inset

 distinct and non zero eigenvalues) 
\begin_inset Formula 
\begin{equation}
p(\lambda)=\prod_{i=1}^{m}\left(\lambda-\lambda_{i}\right)=\lambda^{m}+a_{m}\lambda^{m-1}+\ldots+a_{2}\lambda+a_{1}\label{eq:Polynomial of matrix}
\end{equation}

\end_inset

and the Lagrange's polynomial interpolation formula 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Lagrange's polynomial"

\end_inset

 we can rewrite the 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $b_{jk}$
\end_inset

 in terms of 
\begin_inset Formula $a_{k}$
\end_inset

.
 To make the expression simple, we may also use the polynomial defined in
 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:intermindia polynomial"

\end_inset

.
 Therefore, 
\begin_inset Formula 
\begin{equation}
\mathbf{h}=\frac{\left[c_{1,m},c_{1,m-1},\ldots,c_{1,2}\right]}{\sum_{k=1}^{m}c_{1,k}}\label{eq:Consensus Find coeff. c}
\end{equation}

\end_inset

more specifically, we have 
\begin_inset Formula $c_{1,k}=1+\sum_{j=k+1}^{m}a_{j}$
\end_inset

.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
This make it is possible for the adaptive filter to estimate the consensus
 value by after all coefficients converge.
 
\end_layout

\begin_layout Subsubsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Finite-time-Consensus-on"

\end_inset

Finite-time Consensus on generalized condition
\end_layout

\begin_layout Standard
Suppose the history of local values at node 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $x_{i}\left(k\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is available at node 
\begin_inset Formula $i$
\end_inset

 after running one instance of FO-DCA algorithm.
 Let the Toeplitz matrix be
\begin_inset Formula 
\[
T=\left[\begin{array}{cccc}
x_{i}\left(k\right) & x_{i}\left(k-1\right) & \ldots & x_{i}\left(k-r\right)\\
x_{i}\left(k+1\right) & x_{i}\left(k\right) & \cdots\\
\vdots & \vdots & \ddots & \vdots\\
x_{i}\left(k+r-1\right) & x_{i}\left(k+r-2\right) & \cdots & x_{i}\left(k-1\right)\\
x_{i}\left(k+r\right) & x_{i}\left(k+r-1\right) & \cdots & x_{i}\left(k\right)
\end{array}\right]
\]

\end_inset

and 
\begin_inset Formula $\mathbf{a}=\left[a_{r},\ldots,a_{1},a_{0}\right]^{T}$
\end_inset

, 
\begin_inset Formula $\mathbf{y}=\left[x\left(k+1\right),x\left(k+2\right),\ldots,x\left(k+r+1\right)\right]^{T}$
\end_inset

.
 Then they can be written in a matrix notation as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{y}=T\mathbf{a}\label{eq:Toepliz Eq.}
\end{equation}

\end_inset

 Toeplitz matrix is a special type of matrix.
 It can be inverted by some algorithm in the polynomial time of order 
\begin_inset Formula $N^{2}$
\end_inset

, rather than the order of 
\begin_inset Formula $N^{3}$
\end_inset

 in general case (for example by LU decomposition).
 This is an enormous computational saving.
 Levinson developed a recursive algorithm to solve the system quickly if
 the Toeplitz matrix is symmetric.
 However, the fact that the method can be generalized to the non-symmetric
 case is not well known until it is stated in texts 
\begin_inset CommandInset citation
LatexCommand cite
key "Robinson2000"

\end_inset

.
 Therefore, we can still invert this Toeplitz matrix using Levinson's method.
 
\end_layout

\begin_layout Standard
Now the requirement for node 
\begin_inset Formula $i$
\end_inset

 to solve Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Toepliz Eq."

\end_inset

 is having sufficient local values.
 Once this is satisfied, node 
\begin_inset Formula $i$
\end_inset

 can solve the equation and obtain the set of coefficients 
\series bold

\begin_inset Formula $\mathbf{a}$
\end_inset


\series default
 and construct the polynomial 
\begin_inset Formula 
\[
p(\lambda)=\lambda^{r+1}+a_{r}\lambda^{r}+\ldots+a_{1}\lambda+a_{0}
\]

\end_inset

If the weight matrix have one simple eigenvalue equals to one, the consensus
 finding filter can be easily obtain by defining another polynomial 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
q\left(\lambda\right)=\frac{p\left(\lambda\right)}{\lambda-1}=c_{m}\lambda^{m-1}+c_{m-1}\lambda^{m-2}+\ldots+c_{2}\lambda+c_{1}
\]

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
and the consensus filter to be construct is given by the coefficient in
 the new polynomial 
\begin_inset Formula 
\[
\mathbf{h}=\frac{\left[c_{m},c_{m-1},\ldots,c_{2}\right]}{\sum_{k=1}^{m}c_{k}}
\]

\end_inset

where 
\begin_inset Formula $c_{k}=1+\sum_{j=k+1}^{m}a_{j}$
\end_inset

.
 
\end_layout

\begin_layout Standard
It totally needs 
\begin_inset Formula $2r+2$
\end_inset

 local values and 
\begin_inset Formula $2r+1$
\end_inset

 iterations to construct the Toeplitz matrix and Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Toepliz Eq."

\end_inset

, but all the local value can be obtained from one instance of FO-DCA.
 In contract, the the original finite-time consensus algorithm in 
\begin_inset CommandInset citation
LatexCommand cite
key "Sundaram2007"

\end_inset

 requires 
\begin_inset Formula $r$
\end_inset

 iterations of FO-DCA for each instance, and totally 
\begin_inset Formula $r$
\end_inset

 instances.
 Therefore, the proposed method has some improvement to the original finite-time
 consensus algorithm.
 
\end_layout

\begin_layout Standard
One interesting advantage of this method is that it can also apply to the
 case when weight matrix is non-symmetric.
 It can be demonstrated by just finding the inverse of a confluent Vandermonde
 matrix.
 In examining the inverse of confluent Vandermonde matrix and find the the
 expression of the row who corresponds to the unity eigenvalue, we note
 that the difference is that the length of consensus filter.
 It is not equal to the number of distinct and nonzero eigenvalues 
\begin_inset Formula $m$
\end_inset

, but equal to the sum of all orders in minimal polynomial of weight matrix
 
\begin_inset Formula $\sum_{i=1}^{m}r_{i}$
\end_inset

.
 However, the relationship of local value predictor and consensus finding
 filter still holds.
 Therefore, the proposed method and doesn't need to change and generalizes
 to the non-symmetric weight matrix case.
 
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Consensus Based Signal Processing
\end_layout

\begin_layout Standard
Based on the FT-DCA algorithm we introduced in the last section, actually
 each node can extract more information from local values sequence, if some
 signal processing techniques are used.
 These signal processing techniques introduced in the following may also
 be applied to wireless sensor networks as they could be carried out distributiv
ely.
 
\end_layout

\begin_layout Subsection
Consensus Based Network Information Flooding 
\end_layout

\begin_layout Standard
The conventional information flooding actually is done by copy information
 to all other nodes in the network.
 Each node maintains a table of the values of all nodes in the network,
 initialized with its own node value.
 And nodes exchanges the tables of their own and those from their neighbors
 in each iteration.
 After a certain number of iterations which is equal to the diameter of
 the network, each node will knows value of all the nodes.
 It is also a method to implement distributed averaging.
 
\end_layout

\begin_layout Standard
However, copying information and forwarding to all other nodes takes too
 much resources for the networks.
 If a networks has 
\begin_inset Formula $n$
\end_inset

 nodes, the conventional flooding will needs at least 
\begin_inset Formula $\left(n-1\right)$
\end_inset

 copies for each piece of information.
 And this estimation doesn't considering the cost in transmitting the informatio
n to the destination.
 Therefore, in this section we propose a novel network information flooding
 technique based on consensus algorithm.
 It doesn't require copying information for many time, but transmit information
 by broadcasting.
 The advantage of this method is that it can save the costs in copying and
 transmitting information.
 
\end_layout

\begin_layout Standard
Suppose the network weight matrix is 
\begin_inset Formula $ W$
\end_inset

 that satisfies the same condition 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:convege condition W"

\end_inset

.
 Recall the initial local value decomposition given in Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:initial vector decompose"

\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\begin{equation}
\mathbf{x}\left(0\right)=\sum_{j=1}^{n}\alpha_{j}\mathbf{e}_{j}\label{eq:initial vector decompose}
\end{equation}

\end_inset

which shows that the 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
initial
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 local value vector can be defined by a set of coefficients and a new basis
 defined by the eigenvectors.

\family default
\series bold
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\series default
In addition, the eigenvectors 
\begin_inset Formula $\mathbf{e}_{i}$
\end_inset

 are only depends on the weight matrix.
 Therefore,
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 once the coefficients 
\begin_inset Formula $\alpha_{i}$
\end_inset

 and weight matrix are available, the initial values vector 
\begin_inset Formula $\mathbf{x}\left(0\right)$
\end_inset

 can be calculated.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
It is possible to exchange information between nodes in the network without
 copying information to all other nodes.
\end_layout

\begin_layout Standard
To show how this method can be carried out distributively, recall the FT-DCA
 algorithm in section 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none

\begin_inset CommandInset ref
LatexCommand eqref
reference "sub:Find-the-Consensus"

\end_inset

.
 Let the sample vector 
\begin_inset Formula $\mathbf{y}_{i}(k,d)\in R^{d}$
\end_inset

 is defined by the history of 
\begin_inset Formula $x_{i}(k),$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{y}_{i}(k,d)=\left[x_{i}(k),x_{i}(k-1),\ldots x_{i}(k-d+1)\right]^{\mathrm{T}}
\end{equation}

\end_inset

and the coefficients vector 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathbf{a}=\left[\alpha_{1},\alpha_{2},\ldots,\alpha_{n}\right]^{T}$
\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 If we involve the eigenvectors and redefine the 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Vander matrix and consensus-d*m"

\end_inset

 by 
\begin_inset Formula 
\begin{equation}
\mathbf{y}_{i}(k,d)=\mathbf{V}_{i}(k,d)diag\left(\left[\mathbf{e}_{1}^{T}\mathbf{u}_{i},\mathbf{e}_{2}^{T}\mathbf{u}_{i},\ldots,\mathbf{e}_{n}^{T}\mathbf{u}_{i}\right]\right)\mathbf{a}\label{eq:Vander*Eigen i^th*Alpha}
\end{equation}

\end_inset

where
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $\mathbf{u}_{i}$
\end_inset

 is the unit vector with all zero except the 
\begin_inset Formula $i^{th}$
\end_inset

 component is one, 
\begin_inset Formula $\mathbf{e}_{j}^{T}\mathbf{u}_{i}$
\end_inset

 means the 
\begin_inset Formula $i^{th}$
\end_inset

 component of 
\begin_inset Formula $\mathbf{e}_{j}$
\end_inset

.
 Solving the above equation will obtain the coefficients 
\begin_inset Formula $\alpha_{j}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The consensus based information flooding is ideally suitable for time-invariant
 network.
 Because a node must know all the eigenvectors and eigenvalues of the network
 before it can estimate initial values of other nodes.
 This requires each node flooding its weight coefficients to all nodes in
 the network at first.
 However, instead of flooding the table of initial values, flooding the
 weight matrix is only performed at the stage of network initialization
 or when the network topology changes.
 If the frequency of topology is very low or in a range that acceptable,
 the proposed method could have lower cost both in computation and communication.
\end_layout

\begin_layout Subsection
Consensus Based Decentralized Eigenvalues Estimation 
\end_layout

\begin_layout Standard
In ad-hoc network, each node has the knowledge of network topology is a
 strong condition.
 Although nodes in the network can flood the table of their adjacent nodes
 to build up network topology, it is still a problem to maintain this table
 when the network topology changes frequently.
 
\end_layout

\begin_layout Standard
However, in the distributed signal processing and multi-vehicle cooperative
 control 
\begin_inset CommandInset citation
LatexCommand cite
key "Fax2004"

\end_inset

, the knowledge about network topology is sometimes very important.
 In these applications, the distributed consensus algorithm is widely used
 and requires knowledge of the graph matrix to optimize the convergence
 rate.
 For example, 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset

 proposed a method to find the optimal matrix for FO-DCA which requires
 the whole network topology.
 Even thought higher-order distributed average consensus algorithm doesn't
 have so strong requirement, but the eigenvalues of the graph matrix or
 Laplacian matrix are required 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiong2010"

\end_inset

.
 The paper 
\begin_inset CommandInset citation
LatexCommand cite
key "Chung2006"

\end_inset

 introduce a method to estimate the range of eigenvalues of Laplacian matrix.
 However, this method is still questionable in application due to the following
 reasons.
 First, the range is not accurate enough to satisfy the requirement of convergen
ce rate optimization.
 Second, it requires many communication resources in the transmission of
 node degree and computation of minimum spanning tree.
 Third, it cannot estimate the range for all the eigenvalues, as higher-order
 DAC algorithm need to use more eigenvalues.
\end_layout

\begin_layout Standard
Some sophisticated algorithm, such as the finite-time consensus 
\begin_inset CommandInset citation
LatexCommand cite
key "Sundaram2007"

\end_inset

 and adaptive filter algorithm for consensus 
\begin_inset CommandInset citation
LatexCommand cite
key "Cavalcante2010"

\end_inset

, can converge to the consensus value using an adaptive filter or even find
 the consensus value in finite number of iterations.
 However, it has been proved that the consensus value can be a linear combinatio
n of local values obtained by FO-DCA.
 Thus, the accuracy of the estimated consensus value highly relies on the
 accuracy of coefficients multiplying these local values.
 The reliability to network changes of these methods is still questionable.
 In addition, all these methods have a instance of FO-DCA running in background.
 Therefore, it is very hard to say that the asymptotic consensus algorithms
 are out of time.
 In contract, they are already applied to network with a large number of
 nodes and robust to the topology variation.
 
\end_layout

\begin_layout Standard
If the network topology and all the weights to edges are known to some centraliz
ed nodes in the network, then the eigenvalues can be calculated and flooded
 to all nodes, which could use these values to optimize the convergence
 rate of DCA or even achieve distributed consensus in finite-time.
 However, in some cases there is no such a centralized node to collect all
 the information and doing the calculation and transmission of parameters.
 Therefore, it is necessary for nodes to estimate these parameters with
 local information they can access.
\end_layout

\begin_layout Standard
The work of this section is as follows, first we analyze the properties
 of local value iteration and proposed an algorithm to estimate these necessary
 eigenvalues based on FO-DCA.
 Second, we try to use the estimated eigenvalue to increase the convergence
 rate of the original asymptotic consensus algorithm.
 
\end_layout

\begin_layout Standard
Suppose we have a distributive network with the same system model described
 in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sec:Consensus-problem-on"

\end_inset

.
 The weight matrix satisfies the condition Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:convege condition W"

\end_inset

.
 Then, the minimal polynomial of the weight matrix an unique eigenvalue
 equal to one 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
p(\lambda)=\prod_{i=1}^{m}\left(\lambda-\lambda_{i}\right)=\lambda^{m}+a_{m}\lambda^{m-1}+\ldots+a_{2}\lambda+a_{1}
\]

\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
By letting the 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $p(\lambda)=0$
\end_inset

 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
and finding the solution, 
\begin_inset Formula $\lambda_{i}$
\end_inset

 are the eigenvalues to be estimated.

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
Therefore, the eigenvalues estimation problem is equivalent to the problem
 of finding the coefficients 
\begin_inset Formula $\left\{ a_{m}\right\} $
\end_inset

.
 
\end_layout

\begin_layout Standard
Since coefficients 
\begin_inset Formula $\left\{ a_{m}\right\} $
\end_inset

 also lead to a linear combination expression given in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:local value linear predictor"

\end_inset

.
 They can be estimated by the inverse Toeplitz matrix and solving Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Toepliz Eq."

\end_inset

.
 
\end_layout

\begin_layout Standard
However, when network contains more nodes and the matrix size becomes larger,
 the matrix is almost singular or loss rank so that the numerical error
 of the coefficients becomes larger.
 Even though sometimes it may be accurate enough to estimate the consensus
 value with high accuracy, it is unacceptable for eigenvalues estimation.
 This is because 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $p(\lambda)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is a high order polynomial which is very sensitive to the numerical error
 of its coefficient.
 Thus, the variation of the solutions is much larger than numerical error
 of these coefficients.
 
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
Take a deep inspection of the Toeplitz matrix when it becomes large, one
 of the several reasons for the numerical problem is because the local value
 
\begin_inset Formula $x_{i}\left(k\right)$
\end_inset

 approaches the global average asymptotically, as the it has 
\begin_inset Formula $\left\Vert \mathbf{x}\left(k+1\right)-\mathbf{\bar{x}}\right\Vert <\left\Vert \mathbf{x}\left(k\right)-\mathbf{\bar{x}}\right\Vert $
\end_inset

.
 Thus, the corresponding row in Toeplitz matrix have entries with very little
 difference.
  
\end_layout

\begin_layout Standard
To mitigate the numerical problems, the Toeplitz matrix should be constructed
 by some other way.
 Not only by the local values obtained from one instance of FO-DCA, but
 also from other FO-DCA iterations.
 When the old local values vector is getting too close to the consensus
 values.
 the FO-DCA is reinitialized with a new local value vector which is preferable
 to be independent of the old one.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\mathbf{x}_{1}\left(0\right),\mathbf{x}_{2}\left(0\right),\ldots,\mathbf{x}_{N}\left(0\right)$
\end_inset

 denote 
\begin_inset Formula $N$
\end_inset

 different and independent initial local value vectors.
 For each initial vector the FO-DCA take at least 
\begin_inset Formula $2D+1$
\end_inset

 iterations, where 
\begin_inset Formula $D+1$
\end_inset

 is the width of Toeplitz matrix.
 Due to the property of minimal polynomial of weight matrix, the 
\begin_inset Formula $D$
\end_inset

 should be larger or equal to the number of distinct and nonzero eigenvalues
 of the weight matrix 
\begin_inset Formula $\left(D\geq m\right)$
\end_inset

.
 After this initialization, each node 
\begin_inset Formula $i$
\end_inset

 will have the history of local values obtained by the 
\begin_inset Formula $N$
\end_inset

 instance of FO-DCA.
 Therefore the new Toeplitz matrix can be constructed by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
T=\left[\begin{array}{c}
T_{i,1}\\
T_{i,2}\\
\\
T_{i,N}
\end{array}\right],\mbox{where }T_{i,j}=\left[\begin{array}{cccc}
x_{i,j}\left(D\right) & x_{i,j}\left(D-1\right) & \ldots & x_{i,j}\left(0\right)\\
x_{i,j}\left(D+1\right) & x_{i,j}\left(D\right) & \cdots & x_{i,j}\left(1\right)\\
\vdots & \vdots & \ddots & \vdots\\
x_{i,j}\left(2D\right) & x_{i,j}\left(2D-1\right) & \cdots & x_{i,j}\left(D\right)
\end{array}\right]
\]

\end_inset

Similarly to Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Toepliz Eq."

\end_inset

, the vector 
\begin_inset Formula $\mathbf{y}=\left[\mathbf{y}_{i,1}^{T},\mathbf{y}_{i,2}^{T},\ldots,\mathbf{y}_{i,j}^{T}\right]^{T}$
\end_inset

 is constructed by the corresponding local values, where 
\begin_inset Formula $\mathbf{y}_{i,j}=\left[x_{i,j}\left(D+1\right),x_{i,j}\left(D+2\right),\dots,x_{i,j}\left(2D+1\right)\right]^{T}.$
\end_inset

 Thus, we have the new equation give by 
\begin_inset Formula 
\begin{equation}
\mathbf{y}=T\mathbf{a}\label{eq:expanded Toeplitz Eq.}
\end{equation}

\end_inset

Solving the above equation will involve the Moore-Penrose pseudo-inverse
 
\begin_inset CommandInset citation
LatexCommand cite
key "Piziak2007"

\end_inset

.
 it worth noting that Moore-Penrose pseudo-inverse of 
\begin_inset Formula $T$
\end_inset

 actually find the least mean square solution.
 If we take more initial local value vectors and run more instances of FO-DCA,
 the numerical solution of this equation could be more close to the real
 solution.
 
\end_layout

\begin_layout Subsection
Consensus based Data Fusion and Decision Making
\end_layout

\begin_layout Standard
Sensor networks have a variety of applications in surveillance and environment
 monitoring, data gathering from spatially distributed sources, collaborative
 signal processing.
 A fundamental problem in sensor network is to process the local acquired
 data or signal using a scalable algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "Olfati-Saber2005a"

\end_inset

.
 
\end_layout

\begin_layout Standard
Generally, there are two options for multiple sensors signal processing:
 First option is centralized signal processing.
 This requires the network contains a fusion center, and all sensor's informatio
n being transmuted to the central processor where the global LLR is calculated.
 At the same time, a hypothesis test based on the ML, MAP or Bayesian decision
 rule will be carried out at the a fusion center to make the decision.
 Besides, an optimal data fusion scheme is proposed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Chair1986"

\end_inset

, the decision is made by an optimal linear combination of local decisions
 of all sensors.
 
\end_layout

\begin_layout Standard
The Second option is distributive signal processing.
 In the consideration of reliability, survivability, and increase in range
 of coverage, there is an increasing interest in employing multiple sensors
 for these applications 
\begin_inset CommandInset citation
LatexCommand cite
key "Chair1986"

\end_inset

.
 Then, global LLR should be calculated in a distributive manner.
 In this section, we will consider a distributed detection problem in wireless
 sensor network without the fusion center.
 Then, there will be a introduction about consensus based approach in the
 distributed data fusion and decision making, in the case of each sensor
 acquires a scale value of an unknown parameter.
 However, 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2005"

\end_inset

 discussed the case when each sensor acquires a vector of unknown parameters
 and the signal is mixed with joint Gaussian white noise, and proposed a
 more sophisticated data fusion scheme.
 
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
Considering a binary hypothesis testing problem with the following two hypothese
s
\end_layout

\begin_layout Enumerate
H0: target is absent
\end_layout

\begin_layout Enumerate
H1: target is present.
\end_layout

\begin_layout Standard
Suppose each sensor has the following observation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x_{l}=\begin{cases}
\mu_{l,0}+n_{l} & \mbox{if no target presents}\\
\mu_{l,1}+n_{l} & \mbox{if target presents}
\end{cases}
\end{equation}

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mu_{l,m}$
\end_inset

 is 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
the mean value of 
\begin_inset Formula $x_{l}$
\end_inset

 depending on hypothesis 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $n_{l}$
\end_inset

 is the noise of 
\begin_inset Formula $x_{l}$
\end_inset

 .
 we need to make a declaration of the target presentation or absence based
 on sensors local observations.
 The prior probability of these two hypotheses is denoted by 
\begin_inset Formula $P\left(H_{m}\right)=P_{m},m=1,2$
\end_inset

.
\end_layout

\begin_layout Standard
Based on classical hypothesis test theory, the global log likelihood ratio
 (G-LLR ) test is given by 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
LLR(x_{1},...,x_{L})=\log\frac{f\left(x_{1},...,x_{L}|H_{1}\right)}{f\left(x_{1},...,x_{L}|H_{0}\right)}\underset{H_{0}}{\overset{H_{1}}{\gtrless}\log}\frac{P\left(H_{o}\right)}{P\left(H_{1}\right)}\label{eq:G-LLR define}
\end{equation}

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $f\left(x_{1},...,x_{L}|H_{m}\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is the likelihood function of hypothesis 
\begin_inset Formula $H_{m}$
\end_inset

.
\end_layout

\begin_layout Standard
To calculate the LLR in a distributed manner, an usual simplification is
 assuming sensor observations are independent from one to another.
 Therefore, we have 
\begin_inset Formula $f\left(x_{1},...,x_{L}|H_{m}\right)=f\left(x_{1}|H_{1}\right)\cdot\ldots\cdot f\left(x_{L}|H_{1}\right)$
\end_inset

, and 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
LLR(\mathbf{x}) & = & \log\frac{f\left(x_{1}|H_{1}\right)\cdot\ldots\cdot f\left(x_{L}|H_{1}\right)}{f\left(x_{1}|H_{0}\right)\cdot\ldots\cdot f\left(x_{L}|H_{0}\right)}=\sum_{i=1}^{L}LLR\left(x_{i}\right)\label{eq:Sum L-LLR}
\end{eqnarray}

\end_inset

.
 As seen from the above equation, in another option of data processing,
 if the sensor node could calculate its local log likelihood ratio instead
 of the complete local observation 
\begin_inset Formula $x_{i}$
\end_inset

 , the G-LLR changes into the sum of local log likelihood ratio (L-LLR).
 
\end_layout

\begin_layout Standard
According to Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Sum L-LLR Cloud"

\end_inset

, the G-LLR is equal to the average multiply with the number of sensors
 in the network.
 Therefore, it can be calculated by distributed average consensus (DAC)
 algorithm.
 This is implemented by the following steps: First, each sensor calculates
 its local LLR individually; Then, all the sensors update their local LLR
 in the DAC iteration until they converge to a common value; Finally, once
 the algorithm converges, the global LLR is obtained by multiply the average
 local LLRs with the number of sensors in the network.
 
\end_layout

\begin_layout Standard
In the next, we will generalize the conditions step by step and drive some
 expressions to show the possibility of calculating G-LLR with DAC algorithm.
 First we assume the sensors observation is corrupted by joint Gaussian
 white noise 
\begin_inset Formula $\mathbf{n}\sim\mathcal{N}\left(0,\Sigma\right)$
\end_inset

, which means noises are not independent from one sensor to another.
 Based on this assumption, the expression of G-LLR evolves into a weighted
 sum of sensors observation.
 In section 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:Distributed-Cloud-Declaration"

\end_inset

, we will take a further step.
 The sensor observations will be mixed with joint Gaussian white noises
 which is not only dependent among other sensors but also depends on the
 target existence.
 More results about the applying DAC algorithm in decision making will be
 presented.
 
\end_layout

\begin_layout Standard
Let the sensors observation, the joint Gaussian white noises and the mean
 of sensors observation in a vector form given by 
\begin_inset Formula 
\[
\mathbf{x}=\left[x_{1},\ldots,x_{L}\right]^{\mathrm{T}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbf{n}=\left[n_{1},\ldots,n_{L}\right]^{\mathrm{T}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{u}_{m}=\left[\mu_{1,m},\ldots,\mu_{L,m}\right]^{\mathrm{T}},\; m=0,1.
\end{equation}

\end_inset

Since 
\begin_inset Formula $\mathbf{n}\sim\mathcal{N}\left(0,\Sigma\right)$
\end_inset

, the likelihood function is to be joint Gaussian function 
\begin_inset Formula $f\left(x_{1},...,x_{L}|H_{m}\right)=\frac{1}{\left(2\pi\right)^{L/2}\left|\Sigma\right|^{\frac{1}{2}}}\exp\left(-\frac{1}{2}\left(\mathbf{x}-\mathbf{u}_{m}\right)^{T}\Sigma^{-1}\left(\mathbf{x}-\mathbf{u}_{m}\right)\right)$
\end_inset

, the G-LLR becomes, 
\begin_inset Formula 
\begin{eqnarray}
LLR(\mathbf{x}) & = & \left(\mathbf{u}_{1}^{\mathrm{T}}-\mathbf{u}_{0}^{\mathrm{T}}\right)\mathbf{\Sigma}^{-1}\mathbf{x}+\frac{1}{2}\left(\mathbf{u}_{0}^{\mathrm{T}}\mathbf{\Sigma}^{-1}\mathbf{u}_{0}-\mathbf{u}_{1}^{\mathrm{T}}\mathbf{\Sigma}^{-1}\mathbf{u}_{1}\right)\label{eq:wight sum of detection}\\
 & = & \sum_{l=1}^{L}w_{l}x_{l}+C\nonumber 
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $w_{l}$
\end_inset

 is the 
\begin_inset Formula $l^{th}$
\end_inset

 component of 
\begin_inset Formula $\left(\mathbf{u}_{1}^{\mathrm{T}}-\mathbf{u}_{0}^{\mathrm{T}}\right)\mathbf{\Sigma}^{-1}$
\end_inset

, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $C$
\end_inset

 is the last term the equation.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 This equation means the LLR can be a weighted sum of the signal acquired
 in each sensor.
\end_layout

\begin_layout Standard
Provided that each sensor knows the weight 
\begin_inset Formula $w_{l}$
\end_inset

, the Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:wight sum of detection"

\end_inset

 states that the G-LLR is equal to the weighted sum of local observation
 of sensors in the network together with the constant 
\begin_inset Formula $C$
\end_inset

.
 Actually, the constant 
\begin_inset Formula $C$
\end_inset

 changes the threshold of the hypothesis testing and can be subtract from
 both side of hypothesis testing equation.
 Therefore, we modify the hypothesis testing into 
\begin_inset Formula 
\[
\sum_{l=1}^{L}w_{l}x_{l}\underset{H_{0}}{\overset{H_{1}}{\gtrless}}\frac{P\left(H_{o}\right)}{P\left(H_{1}\right)}-C
\]

\end_inset

where an average of the value 
\begin_inset Formula $w_{l}x_{l}$
\end_inset

 is obtained by distributed average consensus (DAC) algorithm.
 Then we multiply the average with the number of sensors in the network
 to get 
\begin_inset Formula $\sum_{l=1}^{L}w_{l}x_{l}$
\end_inset

.
 This finish the distributed detection and decision making given the noise
 are jointly white Gaussian.
 More generalized condition of calculating 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $LLR(\mathbf{x})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 when sensor signals are correlated is discussed
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "sub:Distributed-Cloud-Declaration"

\end_inset

.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Distributed Detection of Cloud
\end_layout

\begin_layout Standard
A cloud is a group of liquid or solid particles floated in the air.
 Sometime it contains harmful or dangerous particles so that it needs to
 be observed and tracked.
 Laser technology enables the remote detection of cloud.
 In real environment, the received signals may be interfered by noise or
 corrupt by moving object.
 Thus, a method to use distributed detection is necessary.
 Gaussian plume model is widely used in cloud plume modeling, which could
 be used to describe the mean value of cloud concentration.
 However, the sensor's observation is actually a random process with mean
 and variance values.
 So an expectation-maximization algorithm is adopted to get Gaussian mixture
 model that gives the distribution of the sensor’s observation.
 Then, the decision of cloud existence could be made based on the log likelihood
 ratio.
\end_layout

\begin_layout Subsection
Introduction 
\end_layout

\begin_layout Standard
A cloud is a group of liquid or solid particles floated in the air.
 Sometime it contains harmful or dangerous particles so that it needs to
 be observed and tracked.
 There are various types of sensors can perform the detection.
 According to their types of targets, the detection can be categorized into
 smoke/gas/aerosol detection.
 On the other hand, based on their sensing methods, there are also divided
 into contact detection and remote sensing.
 
\end_layout

\begin_layout Standard
Smoke and gas detection is very common in daily life.
 For example, the fire alarm sensor in building, which is contact sensing
 device.
 When the sensing element contacts with smoke or gas agent, the chemical
 or physical reactions change the electrical characteristics of the sensing
 element.
 Then the alarm is set if the agent's concentration is larger than a threshold.
 
\end_layout

\begin_layout Standard
Smoke detection based on video and image processing is also possible.
 For example, in the wildfire video surveillance, people try to change the
 human based surveillance into automatic smoke/fire detection.
 These intelligent algorithms extract smoke's features based on video signal,
 and then classify the objects in the video as smoke or non-smoke.
 This also attracts much research interest.
 
\end_layout

\begin_layout Standard
Some time, the agent does not directly contact with the sensing element.
 The device pumps in some air and illuminate the air with multiple wavelengths
 to get the absorption spectrum, which normally obtained by a infrared spectrosc
opy.
 Then the concentration or species of the agent can be estimated when prior
 knowledge is available.
 
\end_layout

\begin_layout Standard
When sensors are not able to contact with cloud in the sky, laser technology
 enables the remote detection.
 The concept of remote sensing is very close to that of a spectroscopy.
 It is an optical technology that can measure the distance to a target,
 or other properties of a target by illuminating the target with light,
 often using pulses from a laser.
 The devices typically used for studies of aerosols and clouds remotely
 is called LIDAR.
 
\end_layout

\begin_layout Standard
When the cloud is illuminated by a laser beam, the particles absorb the
 energy and emit fluorescent light, as well as 
\begin_inset Quotes eld
\end_inset

reflect
\begin_inset Quotes erd
\end_inset

 light back to the source (referred as backscatter).
 The back-scattered light wavelength is identical to the transmitted light
 
\begin_inset CommandInset citation
LatexCommand cite
key "Lidar.Wiki.2011"

\end_inset

, and the magnitude of the back-scattered light at the given range depends
 on the back-scatter coefficient of scatterers and the extinction coefficients
 of the scatterers along the path at that range 
\begin_inset CommandInset citation
LatexCommand cite
key "P.M.Hamilton1969"

\end_inset

.
 The 
\begin_inset Quotes eld
\end_inset

fingerprint
\begin_inset Quotes erd
\end_inset

 of the fluorescent light or backscatter can be an evidence of the concentration
 or species of particles in that cloud.
 The microprocessor in the sensor node could identify the received signals,
 and make a declaration of cloud.
 
\end_layout

\begin_layout Standard
In battle field applications, aerosol detection may also related to bio-aerosol
 detection.
 As the bio-aerosol release by a biological weapon is extremely dangerous
 to any biological element in that area.
 It is necessary to detect and discrimination it as soon as possible.
 The detection and discrimination can be done by a remote sensing lidar,
 which illuminate the bio-aerosol  and collect back-scatters by a telescope
 just similar to the spectroscopy.
 Therefore, the agent could be discriminated according to its spectrum.
 In research simulation, the bio-aerosol is often created by spread bacillus
 subtilis spores in the air.
 However, the reflection and extinction coefficients are closely related
 to the particles species and absorption spectrum are different from one
 agent to another.
 To estimate the concentration of an aerosol based on backscatter spectrum
 requires prior knowledge of the wavelength-dependent backscatter coefficients.
 
\end_layout

\begin_layout Standard
There are many challenges in outdoor environment for this method.
 First, the background radiation (for example, sunshine in the day time)
 will ruin the lidar signals.
 But it can be compensated by increase the laser power, add optical filter
 in front of the telescope or tracking the background radiation level.
 Second, the interference of moving objects in the sky like birds and balloons
 will have a very high reflect coefficient compared with gases.
 Third, failure of sensor nodes.
 Because of the properties of sensor nodes, such as energy constrains, vulnerabl
e to intruders, they often malfunction and become unreliable.
 Fourth, Cloud is a diffusive target.
 The diffusion target will have different concentration from one sensor
 to another, so the distribution of cloud has random variables that capture
 the special variation of concentration 
\begin_inset CommandInset citation
LatexCommand cite
key "N.Kh.2004"

\end_inset

.
 Finally, a lidar with discrimination ability is very expensive so that
 it often performs passive detection and discrimination.
 Active detection of the bio-aerosol is taken by some other sensors distributing
 in the battle field.
 So this comes to our problem: detecting the bio-aerosol with sensors distribute
d in the environment with noise and interference.
 
\end_layout

\begin_layout Standard
To overcome unreliability of sensor nodes and interference for outdoor remote
 cloud detection, the distributed detection method could be adopted.
\end_layout

\begin_layout Standard
Signal can be processed distributively by distributed consensus algorithm
 (DCA).
 The word consensus means each node would have an agreement on the declaration
 of the target after the algorithm.
 In addition, each node only broadcast its local value until the algorithm
 converges 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiao2004"

\end_inset

.
 This method can save much energy for nodes that heavy loaded in the data
 gathering.
 
\end_layout

\begin_layout Subsection
Background and System model 
\end_layout

\begin_layout Standard
This section is structured in the following way, section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Cloud-Detection-Scenario"

\end_inset

 shows the system model.
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Received-Signal'-Model"

\end_inset

 illustrates the sensor observation model and explain some techniques in
 distributed detection of cloud.
 In the training stage, expectation-maximization algorithm is used to get
 Gaussian mixture model for sensor observation from background noise and
 target.
 In the following, it is the detection stage, where each sensor calculate
 its local log likelihood ratio, and substitute it into distributed consensus
 algorithm.
 When the algorithm converges, each sensor in the network can have an agreement
 on declaring the cloud or not.
 Finally, simulation and result is give in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Simulation"

\end_inset

.
 To get more real cloud data, 3D fluid animation techniques with turbulence
 flow were used.
 The performance of this detection system is also given.
 It shows the multiple sensor detection will be more reliable in the noisy
 environment.
\end_layout

\begin_layout Subsubsection
Cloud Detection Scenario
\begin_inset CommandInset label
LatexCommand label
name "sub:Cloud-Detection-Scenario"

\end_inset


\end_layout

\begin_layout Standard
In the cloud detection scenario shown by Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Cloud-detection-scenario"

\end_inset

, a source produces cloud in a fixed position with fixed power; a time invariant
 wind velocity parallel to the ground, blows the cloud to the positive direction
 of the x-axis.
 With these parameters available, the Gaussian plume model 
\begin_inset CommandInset citation
LatexCommand cite
key "Lin1996"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "GPM.JA.2011"

\end_inset

 is used to describe the cloud concentrate at any position 
\begin_inset Formula $\left(x,y,z\right)$
\end_inset

.
 On the ground, multiple sensors (1 to 
\begin_inset Formula $L$
\end_inset

) aim to the plume perpendicularly to the ground plane and don't change
 their positions.
 The positions were chosen so that the laser beams can penetrate into the
 plume and backscatters are observed by the laser receivers.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/SystemModel/SysModel1.pdf
	width 7cm
	BoundingBox 0bp 0bp 342bp 225bp
	clip

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Cloud-detection-scenario"

\end_inset

Cloud detection scenario
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/GaussianPlumeImage/A9RF2DF.tmp.pdf
	lyxscale 20
	width 7cm
	BoundingBox 20bp 10bp 1840bp 1210bp
	clip

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "cap:GaussianPlume"

\end_inset

Gaussian plume model.
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
System model
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Diffusive Cloud Model
\end_layout

\begin_layout Standard
Since 1970's, The Gaussian plume model is widely used in cloud plume concentrati
on modeling, which can describe the mean value of the cloud concentration
 at any position 
\begin_inset CommandInset citation
LatexCommand cite
key "Shieh1972"

\end_inset

.
 However, The cloud concentration is actually a random process in a real
 plume, the Gaussian plume model can not describe its variance.
 If we observing the real cloud plume for a long time and take the average,
 the result is Gaussian plume model.
 
\end_layout

\begin_layout Standard
With the computer graphic technology of 3D fluid simulation 
\begin_inset CommandInset citation
LatexCommand cite
key "He2011"

\end_inset

, a 3D cloud animation is implemented to get more real cloud plume while
 fluid dynamics and wind turbulence is considered.
 
\end_layout

\begin_layout Standard
This section first introduce the Gaussian plume model mentioned in some
 state-of-art applications.
 Then, some expressions are driven based on the diffusive equations to obtain
 the modified Gaussian plume model especially for laser detection.
 Finally, cloud targets are generated by 3D cloud animation.
 A bunch of cloud plumes is simulated to generate enough data of cloud concentra
tion for algorithm testing.
 
\end_layout

\begin_layout Paragraph
Gaussian Plume Model 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "N.Kh.2004"

\end_inset

 gives a model of the concentration values 
\begin_inset Formula $C$
\end_inset

 of pollutants to be emitted by point instantaneous source at height 
\begin_inset Formula $H$
\end_inset

, described by the normal (Gaussian) distribution 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
C(x,y,z,t) & = & \frac{Q}{(2\pi)^{3/2}\sigma_{x}\sigma_{y}\sigma_{z}}\exp\left(\tfrac{-\left(x-ut\right)^{2}}{2\sigma_{x}^{2}}\right)\exp\left(\tfrac{-\left(y-vt\right)^{2}}{2\sigma_{y}^{2}}\right)...\label{eq:Point source concentration}\\
 &  & \left(\exp\left(\tfrac{-\left(z-H-wt\right)^{2}}{2\sigma_{z}^{2}}\right)+\exp\left(\tfrac{-\left(z+H-wt\right)^{2}}{2\sigma_{z}^{2}}\right)\right)
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $t$
\end_inset

 is the time, 
\begin_inset Formula $Q$
\end_inset

 the source emission power, 
\begin_inset Formula $u,v,w$
\end_inset

 are the orthogonal components of wind velocity, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\sigma_{x},\sigma_{y},\sigma_{z}$
\end_inset

 are the horizontal and vertical dispersions, 
\begin_inset Formula $H$
\end_inset

 the source height .

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\end_layout

\begin_layout Standard
To describe the continuous cloud source emitted into the air.
 An integration form 
\begin_inset Formula $t=0$
\end_inset

 to 
\begin_inset Formula $\infty$
\end_inset

 is taken for Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Point source concentration"

\end_inset

.
 So for continuous source the model is not related to the time 
\begin_inset Formula $t$
\end_inset

,  The model after integration is called Gaussian plume model.
 To make things easy, assume the wind velocity components 
\begin_inset Formula $v=0,w=0$
\end_inset

.
 The Gaussian plume model changes into
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
C(x,y,z,H) & = & \int_{0}^{\infty}C(x,y,z,t)dt\label{eq:Continous source C}\\
 & = & \frac{Q}{2\pi u\sigma_{y}\sigma_{z}}\exp\left(\tfrac{-y^{2}}{2\sigma_{y}^{2}}\right)\left(\exp\left(\tfrac{-\left(z-H\right)^{2}}{2\sigma_{z}^{2}}\right)+\exp\left(\tfrac{-\left(z+H\right)^{2}}{2\sigma_{z}^{2}}\right)\right)\nonumber 
\end{eqnarray}

\end_inset

where
\begin_inset Formula $\sigma_{y}=ax^{b}$
\end_inset

, 
\begin_inset Formula $\sigma_{z}=cx^{d}$
\end_inset

, 
\begin_inset Formula $a,b,c,d$
\end_inset

 are the coefficients which relate to the atmospheric stability are shown
 in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:The-parameter-of"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:The-parameter-of"

\end_inset

The parameter of a,b,c,d according to atmospheric stability
\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Atmospheric stability 
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
a
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
b
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
c
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
d
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.527
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.865
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.28
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.90
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.371
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.866
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.23
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.85
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
C
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.209
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.897
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.22
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.80
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
D
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.128
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.905
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.76
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
E
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.098
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.902
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.15
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.73
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
F
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.065
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.902
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.15
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.73
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
G
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.046
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.902
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.62
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Modified Gaussian Plume Model For Laser Detection
\end_layout

\begin_layout Standard
Because laser emitted by optical sensor is penetrating the could, the received
 signal at each sensor can be simplified to be proportional to the integration
 of concentration along the line of laser.
 Therefore, based on the same diffusion equation, the Gaussian plume model
 needs some modifications.
 
\end_layout

\begin_layout Standard
Similar to the heat diffusion model, the cloud's diffusive behavior can
 be described by the 3-dimensional partial derivative equation.
 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\begin{equation}
\frac{\partial C}{\partial t}=D_{x}\frac{\partial^{2}C}{\partial^{2}x}+D_{y}\frac{\partial^{2}C}{\partial^{2}y}+D_{z}\frac{\partial^{2}C}{\partial^{2}z}\label{eq:3D diffusion Eq.}
\end{equation}

\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
where 
\begin_inset Formula $C$
\end_inset

 is cloud concentration, and 
\begin_inset Formula $D_{x},D_{y},D_{z}$
\end_inset

 are the diffusion coefficients along three axis respectively.
 
\end_layout

\begin_layout Standard
This equation indicates that the rate of density change is proportional
 to the curvature of cloud concentration.
 The density increases where curvature is positive and decreases where it
 is negative.
 If the cloud is released instantaneously at a single point, the spatial
 distribution will be a 3-dimensional normal distribution.
\end_layout

\begin_layout Standard
In consideration of the isotropic diffusion case, the diffusion equation
 can be simplified.

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
which means 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $D_{x}=D_{y}=D_{z}=D$
\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 Assume 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
a point instantaneous source,
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 located at the origin starts to release cloud at time 
\begin_inset Formula $t=0$
\end_inset

,
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 the solution to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:3D diffusion Eq."

\end_inset

 is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
C(x,y,z,t)=\frac{Q}{\left(4\pi Dt\right)^{3/2}}exp\left(-\frac{x{}^{2}+y^{2}+z^{2}}{4Dt}\right)
\end{equation}

\end_inset

Where 
\begin_inset Formula $Q$
\end_inset

 is the power of the point source.
 This solution can be verified by taking partial derivative for both sides.
\end_layout

\begin_layout Standard
In addition, if the surrounding air is assumed to be moving towards the
 positive direction of x-coordinate in a constant velocity 
\begin_inset Formula $u$
\end_inset

 .
 The model changes into
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
C(x,y,z,t)=\frac{Q}{\left(4\pi Dt\right)^{3/2}}\cdot exp\left(\frac{(x-ut){}^{2}+y^{2}+z^{2}}{4Dt}\right)\label{eq:3D point Model}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For point and continuous source at origin, an integration form 
\begin_inset Formula $t=0$
\end_inset

 to 
\begin_inset Formula $T$
\end_inset

 is taken to find the concentration distribution.
 The integration of Eq.
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:3D point Model"

\end_inset

 is very hard to find without the help of computer, as in the denominator
 contains 
\begin_inset Formula $t^{\frac{3}{2}}$
\end_inset

.
 However, some later research have found the analytical integration of the
 atmospheric diffusion equation 
\begin_inset CommandInset citation
LatexCommand cite
key "Lin1996"

\end_inset

.
 
\end_layout

\begin_layout Standard
As 
\begin_inset Formula $T\rightarrow\infty$
\end_inset

 , the concentration model for continuous source evolves into
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\begin{eqnarray}
C(x,y,z) & = & \int_{0}^{\infty}C(x,y,z,t)dt
\end{eqnarray}

\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
as the laser penetrate the could, the received signal at each sensor can
 be simplified to be proportional to the integration of concentration along
 the line of laser.
 Therefore, the received signal 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S(x,y)=\int_{-\infty}^{\infty}C(x,y,z)dz=\int_{-\infty}^{\infty}\int_{0}^{\infty}C(x,y,z,t)dtdz
\]

\end_inset

since the 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\int_{-\infty}^{\infty}\int_{0}^{\infty}\left|C(x,y,z,t)\right|dtdz<\infty$
\end_inset

, the integrations can be swapped.
 thus, we have 
\begin_inset Formula 
\[
\int_{-\infty}^{\infty}\int_{0}^{\infty}C(x,y,z,t)dtdz=\int_{0}^{\infty}\int_{-\infty}^{\infty}C(x,y,z,t)dzdt
\]

\end_inset

and 
\begin_inset Formula 
\[
S(x,y)=\frac{Q}{2\pi D}\cdot exp\left(\frac{xu}{2D}\right)\cdot K_{0}\left(\frac{u\sqrt{x^{2}+y^{2}}}{2D}\right)
\]

\end_inset

where 
\begin_inset Formula $K_{0}(z)$
\end_inset

 is the special case of modified Bessel function of the second kind 
\begin_inset Formula $K_{n}(z)$
\end_inset

.
 
\begin_inset Formula $K_{0}(z)$
\end_inset

 is simplified to 
\begin_inset Formula 
\[
K_{0}(z)=\int_{0}^{\infty}\mbox{cos}(z\cdot\mbox{sinh}t)dt=\int_{0}^{\infty}\frac{\mbox{cos}(z\cdot t)}{\sqrt{t^{2}+1}}dt
\]

\end_inset

Therefore, the finial model of concentration at point 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 can be given by 
\begin_inset Formula 
\[
C(x,y)=\frac{Q}{2\pi D}\cdot exp\left(\frac{xu}{2D}\right)\cdot\int_{0}^{\infty}\frac{1}{\sqrt{t^{2}+1}}\mbox{cos}(\frac{u\sqrt{x^{2}+y^{2}}}{2D}\cdot t)dt
\]

\end_inset

The concentration distribution is shown in Figure.
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:2-D-Gaussian-Plume"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/GaussianPlumeModel/Plume_2D.eps
	lyxscale 50
	height 6cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:2-D-Gaussian-Plume"

\end_inset

2-D Gaussian Plume Model (modified for laser detection)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Simulated Cloud by fluid dynamics
\end_layout

\begin_layout Standard
The Gaussian plume model can describe the mean value of the cloud concentration
 at any position in the plume, but it can not describe the cloud concentration
 variance.
 With the help of 3D fluid simulation, a cloud could be more like real while
 fluid dynamics and wind turbulence is considered.
 And this kind of model is simulated to generate a number of cloud plumes.
 The data is used in the distributed cloud detection to training the sensor
 networks.
\end_layout

\begin_layout Standard
As shown in the Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Frame-projection"

\end_inset

, the frame image is obtained by taking integration of the 3D raw data over
 z-dimension.
 This is similar to the effect of laser beam penetrating through cloud.
 The received light magnitude is the integration of backscatter along the
 laser beam.
 Therefore, pixels value in the frame image is proportional to the magnitude
 of sensor observation.
 In this simulation, they are treated as equal.
 After the integration, the pixel values in these frames is normalized by
 dividing them with the maximum pixel value in these frames.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/Smoke Sequance.png
	lyxscale 50
	width 14cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Cloud-simulation-frame"

\end_inset

Cloud simulation frame sequence, 
\begin_inset Formula $192\times256$
\end_inset

 pixels for each frame
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/SmokeProject/SmokeProjection_PhS.pdf
	lyxscale 80
	width 8cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Frame-projection"

\end_inset

Relationship between 3D cloud concentration and Sensor's observation.
 Frame images are obtained by 3D raw data projection 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Subsubsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Received-Signal'-Model"

\end_inset

Received Signal Model 
\end_layout

\begin_layout Standard
As we know, the cloud concentration variation is caused by turbulence flow,
 which is a random process which brings the cloud particles more far away
 than the molecular motion.
 Because of this reason, the cloud concentration at a given position and
 the associated sensor's detection is a random process.
 
\end_layout

\begin_layout Standard
Suppose the sensor's observation has the following form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x_{l}=\begin{cases}
\mu_{l,0}+n_{l,0} & \mbox{if no cloud exists}\\
\mu_{l,1}+n_{l,1} & \mbox{if cloud exists}
\end{cases}
\end{equation}

\end_inset

where
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $\mu_{l,m}$
\end_inset

 is 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
the mean value of 
\begin_inset Formula $x_{l}$
\end_inset

 depending on hypothesis 
\begin_inset Formula $m$
\end_inset

; 
\begin_inset Formula $n_{l,m}$
\end_inset

 is the noise of 
\begin_inset Formula $x_{l}$
\end_inset

 depending on hypothesis 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $n_{l,m}\sim\mathcal{N}\left(0,\sigma_{m}\right)$
\end_inset

.
 Actually, 
\begin_inset Formula $\mu_{l,0}$
\end_inset

and 
\begin_inset Formula $\sigma_{l,0}$
\end_inset

 denote the mean and variation of background noise.
 So let 
\begin_inset Formula $\mu_{t}$
\end_inset

 and 
\begin_inset Formula $n_{t}$
\end_inset

 denote the mean of cloud concentration and cloud turbulent,
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 we have 
\begin_inset Formula $\mu_{l,1}=\mu_{l,0}+\mu_{t}$
\end_inset

, 
\begin_inset Formula $n_{l,1}=n_{l,0}+n_{t}$
\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 These parameters is initialized or calculated in the training stage.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
This received signal model doesn't consider interference of moving objects
 or be covered by obstacles.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 To deal with this problems, sensors may need to build the Gaussian mixture
 model, which introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Gaussian-mixture-model"

\end_inset

.
 
\end_layout

\begin_layout Paragraph
\begin_inset CommandInset label
LatexCommand label
name "par:Gaussian-mixture-model"

\end_inset

Gaussian mixture model
\end_layout

\begin_layout Standard
Background radiation and moving objects in the sky have different strength
 and variance.
 When interference exists, the probability of received signal strength may
 be a mixture Gaussian distribution.
 Gaussian mixture model is a very successful tool in modeling the background
 noise in such situation 
\begin_inset CommandInset citation
LatexCommand cite
key "Stauffer1999"

\end_inset

.
 To build the Gaussian mixture model, the recent history of a sensor's detection
 values is stored.
 Then, Expectation-Maximization(EM) algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "Moon1996"

\end_inset

 can be adopted.
 The model can also be adaptive to track the background changes.
 
\end_layout

\begin_layout Standard
Suppose the recent history of a sensor's detections, are given by 
\begin_inset Formula $\left\{ x_{1},\ldots,x_{t}\right\} $
\end_inset

, which is modeled by a mixture of 
\begin_inset Formula $K$
\end_inset

 Gaussian distributions.
 The probability density function of observing a detection value is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f(\mathbf{x}_{t})=\sum_{i=1}^{K}\omega_{i,t}*\eta(\mathbf{x}_{t},\mu_{i,t},\Sigma_{i,t})\label{eq:GMM density function}
\end{equation}

\end_inset

where 
\begin_inset Formula $K$
\end_inset

 is the number of distributions, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\omega_{i,t}$
\end_inset

 is the weight of the 
\begin_inset Formula $i^{th}$
\end_inset

 Gaussian in the mixture at time 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $\mu_{i,t}$
\end_inset

 is the mean value of the 
\begin_inset Formula $i^{th}$
\end_inset

 Gaussian in the mixture at time 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $\Sigma_{i,t}$
\end_inset

 is the covariance matrix of the 
\begin_inset Formula $i^{th}$
\end_inset

 Gaussian in the mixture at time 
\begin_inset Formula $t$
\end_inset

 , and 
\begin_inset Formula $\eta$
\end_inset

 is a Gaussian probability density function given by
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\begin{equation}
\eta(\mathbf{x}_{t},\mu_{i,t},\Sigma_{i,t})=\frac{1}{\left(2\pi\right)^{\frac{t}{2}}\left|\Sigma\right|^{\frac{1}{2}}}\cdot e^{-\frac{1}{2}\left(\mathbf{x}_{t}-\mu_{t}\right)^{\mathrm{T}}\Sigma^{-1}\left(\mathbf{x}_{t}-\mu_{t}\right)},
\end{equation}

\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
Thus, the distribution of recent detection values are modeled by a mixture
 of Gaussian distribution.
 The recent detections are classified in 
\begin_inset Formula $K$
\end_inset

 categories.
 For the background model, all categories correspond to background noise.
 When a new detection comes, generally it will be matched to one of the
 major components of the model and was used to update the background model.
 If a group of adjacent sensors having detections do not match any categories
 of background model, it is more likely the cloud exists.
 
\end_layout

\begin_layout Standard
Similarly, EM algorithm could also build the Gaussian mixture model for
 the observing when cloud exists.
 In this case, one or more categories will correspond to the detection mainly
 raised by clouds reflection.
 If a group of adjacent sensors having detections match the categories of
 cloud, it is more likely the cloud exists.
 
\end_layout

\begin_layout Standard
Once the probability density function (PDF) for background and cloud reflection
 signals are available, the hypothesis test of cloud existence is made based
 on the observation.
 Normally, this is done by gathering all the data and taking the log likelihood
 ratio(LLR) in the fusion center.
 In section III-C, distributed consensus algorithm is adopted to find the
 LLR, without data gathering or fusion center.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Distributed-Cloud-Declaration"

\end_inset

Distributed Cloud Detection Based on DAC algorithm
\end_layout

\begin_layout Standard
The method is organized in two stage, training and detection.
 The training stage is to build the probability density function (PDF) for
 background radiation and cloud reflection signals (modeled by a Gaussian
 mixture model) based on their own observation distributively.
\end_layout

\begin_layout Standard
Cloud declaration is normally made through a hypothesis test.
 When new observation is acquired, the decision of cloud existence is made
 base on the ML or MAP decision rule 
\begin_inset CommandInset citation
LatexCommand cite
key "Chair1986"

\end_inset

, which need the PDF and all the sensor’s observation.
 In a centralized processing method, these data can be gathered to the fusion
 center to perform the data processing.
 However, they can achieve this distributively without a fusion center.
 However, some conditions should be satisfied to calculating global log
 likelihood ratio (G-LLR) by distributed consensus algorithm without the
 fusion center, and it will be given later.
\end_layout

\begin_layout Standard
Suppose the sensor's observation has the following form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
x_{l}=\begin{cases}
\mu_{l,0}+n_{l,0} & \mbox{if no cloud exists}\\
\mu_{l,1}+n_{l,1} & \mbox{if cloud exists}
\end{cases}\label{eq:Cloud signal model}
\end{equation}

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mu_{l,m}$
\end_inset

 is 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
the mean value of 
\begin_inset Formula $x_{l}$
\end_inset

 depending on hypothesis 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $n_{l,m}$
\end_inset

 is the noise of 
\begin_inset Formula $x_{l}$
\end_inset

 depending on hypothesis 
\begin_inset Formula $m$
\end_inset

.
 Actually, 
\begin_inset Formula $u_{l,0}$
\end_inset

and 
\begin_inset Formula $n_{l,0}$
\end_inset

 denote the mean and variation of background noise.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mu_{l,1}=\mu_{l,0}+u_{t}$
\end_inset

, 
\begin_inset Formula $n_{l,1}=n_{l,0}+n_{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 , 
\begin_inset Formula $u_{t}$
\end_inset

 and 
\begin_inset Formula $n_{t}$
\end_inset

 denote the mean and variation of cloud concentration.
 
\end_layout

\begin_layout Standard
Suppose the observation of all sensors 
\begin_inset Formula $x_{1},...,x_{L}$
\end_inset

 is available (for example, gathered by a fusion center) at this moment,
 we can have the global log likelihood ratio (G-LLR ) given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
LLR(x_{1},...,x_{L})=log\frac{f\left(x_{1},...,x_{L}|H_{1}\right)}{f\left(x_{1},...,x_{L}|H_{0}\right)}\label{eq:G-LLR define Cloud}
\end{equation}

\end_inset

where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $f\left(x_{1},...,x_{L}|H_{m}\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is the likelihood function of 
\begin_inset Formula $H_{m}$
\end_inset

.
 
\end_layout

\begin_layout Standard
For the received signal model described either by 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:GMM density function"

\end_inset

 or 
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:Cloud signal model"

\end_inset

, if we assume sensor’s observation is independent from one to another,
 the G-LLR can be changed into the sum of L-LLR.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
LLR(x_{1},...,x_{L}) & = & log\frac{f\left(x_{1}|H_{1}\right)\cdot\ldots\cdot f\left(x_{L}|H_{1}\right)}{f\left(x_{1}|H_{0}\right)\cdot\ldots\cdot f\left(x_{L}|H_{0}\right)}=\sum_{i=1}^{L}LLR\left(x_{i}\right)\label{eq:Sum L-LLR Cloud}
\end{eqnarray}

\end_inset

According to Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Sum L-LLR Cloud"

\end_inset

, the G-LLR is equal to the average multiply with the number of sensors
 in the network.
 Therefore, it can be calculated by distributed average consensus (DAC)
 algorithm.
 This is implemented by the following steps: First, each sensor calculates
 its local LLR individually; Then, all the sensors update their local LLR
 in the DAC iteration until they converge to a common value; Finally, once
 the algorithm converges, the global LLR is obtained by multiply the average
 local LLRs with the number of sensors in the network.
 When the G-LLR is available, cloud declaration could be made based on the
 ML or MAP decision rule.
\end_layout

\begin_layout Standard
To drive and simplify the expression of global log likelihood ratio when
 sensor’s observation which is described by the received signal model in
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Received-Signal'-Model"

\end_inset

, let 
\begin_inset Formula 
\[
\mathbf{x}=\left[x_{1},\ldots,x_{L}\right]^{\mathrm{T}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbf{n}_{m}=\left[n_{1,m},\ldots,n_{L,m}\right]^{\mathrm{T}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{u}_{m}=\left[\mu_{1,m},\ldots,\mu_{L,m}\right]^{\mathrm{T}},\; m=0,1.
\end{equation}

\end_inset

 if 
\begin_inset Formula $\mathbf{n}_{m}\sim\mathcal{N}\left(0,\Sigma_{m}\right)$
\end_inset

, G-LLR becomes, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
LLR(\mathbf{x}) & = & -\frac{1}{2}\left(\mathbf{x}-\mathbf{u}_{1}\right)^{\mathrm{T}}\mathbf{\Sigma}_{1}^{-1}\left(\mathbf{x}-\mathbf{u}_{1}\right)+\frac{1}{2}\left(\mathbf{x}-\mathbf{u}_{0}\right)^{\mathrm{T}}\mathbf{\Sigma}_{0}^{-1}\left(\mathbf{x}-\mathbf{u}_{0}\right)+\frac{1}{2}log\left(\frac{\left|\Sigma_{0}\right|}{\left|\Sigma_{1}\right|}\right)\nonumber \\
 & = & \left(\mathbf{u}_{1}^{\mathrm{T}}\mathbf{\Sigma}_{1}^{-1}-\mathbf{u}_{0}^{\mathrm{T}}\mathbf{\Sigma}_{0}^{-1}\right)\mathbf{x}+\frac{1}{2}\left[log\left|\Sigma_{0}\right|-log\left|\Sigma_{1}\right|\right]\label{eq:G-LLR Expand}\\
 &  & -\frac{1}{2}\left(\mathbf{u}_{1}^{\mathrm{T}}\mathbf{\Sigma}_{1}^{-1}\mathbf{u}_{1}-\mathbf{u}_{0}^{\mathrm{T}}\mathbf{\Sigma}_{0}^{-1}\mathbf{u}_{0}\right)-\frac{1}{2}\left[\mathbf{x}^{\mathrm{T}}\left(\mathbf{\Sigma}_{1}^{-1}-\Sigma_{0}^{-1}\right)\mathbf{x}\right]\nonumber \\
 & = & \sum_{l=1}^{L}w_{l}x_{l}+C-\frac{1}{2}\left[\mathbf{x}^{\mathrm{T}}\left(\mathbf{\Sigma}_{1}^{-1}-\Sigma_{0}^{-1}\right)\mathbf{x}\right],\label{eq:G-LLR simple}
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $w_{l}$
\end_inset

 denotes the 
\begin_inset Formula $l\mbox{th}$
\end_inset

 component of 
\begin_inset Formula $\mathbf{u}_{1}^{\mathrm{T}}\mathbf{\Sigma}_{1}^{-1}-\mathbf{u}_{0}^{\mathrm{T}}\mathbf{\Sigma}_{0}^{-1}$
\end_inset

, and 
\begin_inset Formula $C=\frac{1}{2}\left[log\left(\left|\Sigma_{0}\right|\right)-log(\left|\Sigma_{1}\right|)\right]-\frac{1}{2}\left(\mathbf{u}_{1}^{\mathrm{T}}\mathbf{\Sigma}_{1}^{-1}\mathbf{u}_{1}-\mathbf{u}_{0}^{\mathrm{T}}\mathbf{\Sigma}_{0}^{-1}\mathbf{u}_{0}\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
When no cloud exists, the sensor's observation signal is only caused by
 atmospheric backscatter and noise.
 It is described by joint Gaussian distribution 
\begin_inset Formula $\mathcal{N}\left(\mathbf{u}_{0},\Sigma_{0}\right)$
\end_inset

.
 If these distributions are independent and identical, we have 
\begin_inset Formula 
\begin{equation}
\mathbf{\Sigma}_{0}=\sigma_{0}^{2} I.
\end{equation}

\end_inset

On the contrary, 
\begin_inset Formula $\mathbf{\Sigma}_{1}$
\end_inset

 can't be written in the same form.
 Because the fluctuating amplitude of cloud concentration may different
 from one sensor to another.
 In addition, fluctuating of cloud concentration or sensor's observation
 are correlated, especially for the sensors close to each other.
 As shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:GMM (x1,x2)"

\end_inset

, the correlation is obvious when sensor's observation is shifted with the
 right time delay.
 However, if the training data are available, 
\begin_inset Formula $\mathbf{\Sigma}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathbf{u}_{1}$
\end_inset

 can be obtained by expectation-maximization (EM) algorithm.
 This is more related to sensor learning.
 In real sensing area, sensors should need to learn their environments and
 get these parameters updated and tracked.
 
\end_layout

\begin_layout Standard
In a network without fusion center, it is desirable to find the 
\begin_inset Formula $LLR(\mathbf{x})$
\end_inset

 in a distributed manner by distributed consensus algorithm (DCA).
 Some properties of DCA should emphasize here.
 First values can only be exchanged between neighbors.
 Second, DCA is a tool to find the average of the local values that initially
 hold by all the nodes in the networks.
 
\end_layout

\begin_layout Standard
The quadratic form in Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:G-LLR simple"

\end_inset

 contains high order components of 
\begin_inset Formula $\mathbf{x}$
\end_inset

.
 On the other hand, without global information, it seems not possible to
 calculate 
\begin_inset Formula $\mathbf{\Sigma}_{1}^{-1}$
\end_inset

 in in a distributed manner.
 Both make it is impossible for DCA to calculate G-LLR.
 So sensors can only build the Gaussian mixture model separately.
 Thus, the observation of sensors is assume to be independent from on to
 another.
 If we assume 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\Sigma_{1}=diag\left(\sigma_{1,1}^{2},\sigma_{2,1}^{2},\ldots,\sigma_{L,1}^{2}\right)$
\end_inset

, 
\begin_inset Formula $\Sigma_{0}=\sigma_{0}^{2} I$
\end_inset

, 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
the Eq.
\begin_inset CommandInset ref
LatexCommand formatted
reference "eq:G-LLR Expand"

\end_inset

 evolves into Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Sum L-LLR Cloud"

\end_inset

, in which the G-LLR is equal to the average multiply with the number of
 sensors in the network.
 
\end_layout

\begin_layout Standard
However, the assumption that correlation only exist between sensors located
 very close to each other makes it possible to calculate the G-LLR
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
in Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Sum L-LLR Cloud"

\end_inset

 using DCA.
 As each node only stores the coefficient 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
corresponding to itself.
 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
When signal are correlated, we make approximation that 
\begin_inset Formula $c_{ij}=0,$
\end_inset

 if node 
\begin_inset Formula $i$
\end_inset

 and node 
\begin_inset Formula $j$
\end_inset

 are not neighbors.
 So in the term, 
\begin_inset Formula 
\begin{equation}
\frac{1}{2}\sum_{i=1}^{L}\sum_{j=1}^{L}c_{ij}x_{i}x_{j}\label{eq:Term x_i*x_j}
\end{equation}

\end_inset

we can find the value of Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Term x_i*x_j"

\end_inset

 by the following algorithm:
\end_layout

\begin_layout Enumerate
Assume for all node 
\begin_inset Formula $i$
\end_inset

, it has the value 
\begin_inset Formula $x_{i}$
\end_inset

 and 
\begin_inset Formula $c_{ij}$
\end_inset

.
 As the matrix is symmetric and the entries 
\begin_inset Formula $c_{ij}=c_{ji}$
\end_inset

.
 node 
\begin_inset Formula $i$
\end_inset

 send 
\begin_inset Formula $x_{i}$
\end_inset

 and receive 
\begin_inset Formula $x_{j}$
\end_inset

 from all node 
\begin_inset Formula $j$
\end_inset

 in the neighbors set 
\begin_inset Formula ${\cal N}_{i}$
\end_inset

.
 Compute the value 
\begin_inset Formula 
\begin{equation}
v_{i}=\sum_{j\in{\cal N}_{i}}c_{ij}x_{i}x_{j}+c_{ii}x_{i}^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Initialize a DAC algorithm with 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
local values 
\begin_inset Formula $v_{i}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 until
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 they converges
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 to the average 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\bar{v}=\frac{1}{L}\sum_{i=1}^{L}v_{i}$
\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\end_layout

\begin_layout Enumerate
Start another DAC algorithm to find 
\begin_inset Formula $\bar{u}=\sum_{l=1}^{L}w_{l}x_{l}$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
The G-LLR
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 is 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
equal to 
\begin_inset Formula $\bar{u}+\bar{v+C}$
\end_inset

 multiply with the number of sensors in the network
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
.
\end_layout

\begin_layout Subsection
Simulation
\begin_inset CommandInset label
LatexCommand label
name "sec:Simulation"

\end_inset


\end_layout

\begin_layout Standard
The distributed cloud detection simulation consists of two stages, training
 and detection.
 In the training stage, sensors are trained to build the Gaussian mixture
 models, which are important to calculate the L-LLR.
 After the training, when a new observation comes, all sensors calculated
 the L-LLRs and take them into DCA iteration to obtain G-LLR.
 The decision of cloud existence could be made distributively once the algorithm
 converges.
 
\end_layout

\begin_layout Standard
The 3D cloud animation is simulated to generate a bunch of cloud plumes.
 If we observing the cloud for a long time and take the average, the result
 is Gaussian plume model.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/Mlti_Obs/SensorObs3.pdf

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Sensor's obs"

\end_inset

Sensor's observation impaired by Gaussian white noise
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The cloud animation is simulated several times to generate enough data,
 which is divided into two group for both training and testing of system
 performance.
 Because the turbulence flow is a random process, the data generated each
 time is different with the others in the cloud concentration distribution,
 as well as the cloud particles moving track.
 This provides a very practical testing environment for the system.
 
\end_layout

\begin_layout Standard
Some other consideration for this simulation is that sensors are randomly
 distributed in the sensing area and sensor's detections are impaired by
 Gaussian white noise, which will be introduced in the following.
 
\end_layout

\begin_layout Subsubsection
Sensor's Observation 
\end_layout

\begin_layout Standard
Gaussian white noise impaired the received signal when sensor observing
 the cloud concentration.
 And the source of noise includes: (i) the external noise, arising from
 the incidence of radiation at the detector both from laser scattering and
 from the background; and (ii) the internal noise, arising from fluctuations
 in the detector dark current and thermal noise in the detector load resistor
 
\begin_inset CommandInset citation
LatexCommand cite
key "P.M.Hamilton1969"

\end_inset

.
 These noise is additive, and the overall noise is treated as a Gaussian
 white noise denoted by 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathcal{N}\left(u_{0},\sigma_{0}\right)$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
.
 In this simulation, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
these parameters are chosen as 
\begin_inset Formula $u_{0}=0.3$
\end_inset

 and 
\begin_inset Formula $\sigma_{0}=0.1$
\end_inset

, shown in Fig
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Sensor's obs"

\end_inset

.
\end_layout

\begin_layout Standard
Again, sensors are randomly distributed in the sensing area with the uniform
 distribution.
 The sensing area in this simulation is defined by pixels in the frame which
 has 
\begin_inset Formula $x>D$
\end_inset

, where 
\begin_inset Formula $D$
\end_inset

 is the distance from the cloud source on the downwind direction.
 After they are distributed, to get ready for the DCA algorithm, all the
 nodes will automatically find its neighbors and obtain a network.
 Using DCA algorithm is to obtain G-LLR without copy L-LLRs to all sensor
 nodes in the network.
 Once the G-LLR is available, cloud declaration could be made base on the
 ML or MAP decision rule.
\end_layout

\begin_layout Standard
Here we give an example, three sensors are distributed as shown in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Sensor's obs"

\end_inset

.
 They build Gaussian mixture models by processing the training data.
 Here we choose 
\begin_inset Formula $K=1$
\end_inset

.
 It can be 
\begin_inset Formula $2$
\end_inset

 or more, depends on how many components of the noise in the environment.
 Then, the testing data which generated by another cloud animation is passing
 through all the sensors frame by frame.
 As shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Global-LLR-and"

\end_inset

, L-LLRs for the two sensors and G-LLR is given.
 Before frame 47, all the sensor has no contact with cloud, and only noise
 are presented in each sensor.
 Only after sensor 
\begin_inset Formula $S_{1}$
\end_inset

 has its cloud contact, G-LLR raise to the first stage.
 After 
\begin_inset Formula $S_{2}$
\end_inset

 has its contact of cloud at frame 63, the G-LLR increased to an even high
 level, which is strong evidence of the cloud existence.
 Because 
\begin_inset Formula $S_{3}$
\end_inset

 had no chance to contact with the cloud, its L-LLR is actually less sensitive
 to the sensors signal.
 Thus, its L-LLR has very low contribution to the G-LLR.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/Mlti_Obs/Sensor_LLR_Obs.pdf
	width 14cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Global-LLR-and"

\end_inset

(upper) Global LLR vs.
 Local LLR and (down) Sensor Observation (Only frame 40 to 80 is shown)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Another interesting thing is that, if two sensors 
\begin_inset Formula $S1$
\end_inset

 and 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $S2$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 are put close to each other, especially when they are very nearly located
 on the cloud particle's moving path, their observation have high correlation.
 For example in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Sensor's obs"

\end_inset

 and Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:GMM (x1,x2)"

\end_inset

.
 The time delay 
\begin_inset Formula $\tau$
\end_inset

 is simply calculated by local wind velocity and sensor’s distance.
 The cross-correlation can be another feature of the moving cloud.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/Mlti_Obs/Two Sensors' Correlation.eps
	lyxscale 60
	width 7cm
	height 6cm

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:GMM (x1,x2)"

\end_inset

The distribution of tuples 
\begin_inset Formula $[x_{1}(t),x_{2}(t-\tau)]$
\end_inset

, 
\begin_inset Formula $\tau$
\end_inset

 is the time delay 
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/Mlti_Obs/Two Sensors' Obs.eps
	lyxscale 60
	width 7cm
	height 6cm

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Two-Obs."

\end_inset

Two sensors observation 
\begin_inset Formula $x_{1}(t),x_{2}(t)$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Sensor's observation of background noise and cloud backscatters 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Performance of Cloud Detection Sensor Network
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename D:/Dropbox/PaperWork/CloudDetection/Cloud Detection Task Description/ROC/ROC_mix_RandPos_256x192.pdf
	width 9cm
	height 7.5cm

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:ROC-of-CDWSN"

\end_inset

Detection relative operating characteristic for different sensors numbers
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Simulation is running for hundreds of times to give the average performance
 for different number of sensors in the network.
 The sensor's positions are chosen randomly in the area where 
\begin_inset Formula $x>128$
\end_inset

, The Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ROC-of-CDWSN"

\end_inset

 gives the relative operating characteristic (Also known as a ROC curve)
 of the detection system with different sensors numbers.
 The curve is represented by plotting the fraction of true detection out
 of the cloud exist vs.
 the fraction of false alarm out of the cloud not exist.
 When there is only one sensor is operation, a special case is that the
 position is chosen by hand to make sure the sensor can contact with the
 cloud plume.
 With this assurance, the one sensor detecting system could have performance
 close to the three sensor detecting system randomly distributed.
 The advantage of using distributed detection with multiple sensors is obvious.
 As the detecting system with more sensors is more reliable to noise which
 leads to a higher performance.
 
\end_layout

\begin_layout Subsection
Conclusion
\end_layout

\begin_layout Standard
The simulation of multiple observation shows that the detections of sensors
 are correlated when they are located in short distance.
 The correlation can be an indicate of the cloud plume.
 Because Gaussian noise or Moving object cause very low correlation between
 sensors.
 If this can be recognized, it will not likely to raise the false alarm.
 In the noisy environment, sensors will adopt the expectation-maximization
 algorithm to build the model of background noise and cloud backscatter.
 By assume that sensors observation is independent, the global log likelihood
 ratio is the average of local log likelihood ratio.
 Therefore, global log likelihood ratio can be calculated by distributed
 consensus algorithm, where each sensor take local log likelihood ratio
 into the DCA iteration.
 Once the algorithm converges, the global log likelihood ratio is available
 to each sensor.
 The cloud deceleration could be made distributively based on the ML or
 MAP decision rule.
 
\end_layout

\begin_layout Subsection
Further Research
\end_layout

\begin_layout Standard
In the future research, the parameters of the plume are treated as random.
 Therefore, sensors should be able to estimate these parameters from their
 observation.
 Gaussian plume model can only describe the mean value of a cloud plume.
 So a modified Gaussian plume model should be developed.
 The correlation can be an indicate of the cloud plume and will be considered
 in further research to improve the performance.
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Acknowledgment
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "D:/Dropbox/Citation_DS/EigenValueEstimation,D:/Dropbox/Citation_DS/DistributedConsensus,D:/Dropbox/Citation_DS/Consensus_Finte-Time,D:/Dropbox/Citation_DS/Consensus&Filter,D:/Dropbox/Citation_DS/WirelessSensorNetwork,D:/Dropbox/Citation_DS/SmokeAnimation,D:/Dropbox/Citation_DS/Smoke_Gas_Detection,D:/Dropbox/Citation_DS/PlumeDetection,D:/Dropbox/Citation_DS/GaussianPlumeModel,D:/Dropbox/Citation_DS/DataFusion,D:/Dropbox/Citation_DS/CloudDetection,D:/Dropbox/Citation_DS/Lidar"
options "IEEEtran"

\end_inset


\end_layout

\end_body
\end_document
